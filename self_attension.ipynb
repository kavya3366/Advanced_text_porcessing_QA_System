{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Data Processing ===\n",
      "\n",
      "=== Data Preparation Started ===\n",
      "Successfully read CSV file\n",
      "\n",
      "=== Dataset Information ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   label   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "\n",
      "=== Value Counts for Labels ===\n",
      "label\n",
      "0    144277\n",
      "1     15294\n",
      "Name: count, dtype: int64\n",
      "Loaded 159571 samples\n",
      "\n",
      "=== Building Vocabulary ===\n",
      "Processing 159571 texts\n",
      "\n",
      "--- Vocabulary Statistics ---\n",
      "Total unique words: 251359\n",
      "Most common 10 words:\n",
      "the: 495403\n",
      "to: 296836\n",
      "of: 224012\n",
      "and: 222337\n",
      "a: 214182\n",
      "you: 204486\n",
      "i: 200497\n",
      "is: 175943\n",
      "that: 154272\n",
      "in: 144156\n",
      "\n",
      "Final vocabulary size: 10000\n",
      "Sample word indices:\n",
      "<PAD>: 0\n",
      "<UNK>: 1\n",
      "the: 2\n",
      "to: 3\n",
      "of: 4\n",
      "Created dataset with 159571 samples\n",
      "Created DataLoader with batch size 32\n",
      "\n",
      "=== Sample of Processed Data ===\n",
      "\n",
      "Sample 85845:\n",
      "Original text: No no no no. I meant the tag here: http://en.wikipedia.org/wiki/Hattori_Hanz%C5%8D#In_popular_cultur...\n",
      "Label: 0\n",
      "Tensor shape: torch.Size([512])\n",
      "\n",
      "Sample 64520:\n",
      "Original text: Please stop. If you continue to blank out or delete portions of page content, templates or other mat...\n",
      "Label: 0\n",
      "Tensor shape: torch.Size([512])\n",
      "\n",
      "Sample 157758:\n",
      "Original text: I've gone ahead and implemented the revisions to the lede section discussed above.  Please feel free...\n",
      "Label: 0\n",
      "Tensor shape: torch.Size([512])\n",
      "Vocabulary size: 10000\n",
      "Number of batches: 4987\n",
      "Batch shape: torch.Size([32, 512])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextPreprocessor:\n",
    "    def __init__(self, max_vocab_size=10000, max_seq_length=512):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "        # print(f\"Initialized TextPreprocessor with max_vocab_size={max_vocab_size}, max_seq_length={max_seq_length}\")\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and normalize text\"\"\"\n",
    "        if pd.isna(text):  # Handle NaN values\n",
    "            return \"\"\n",
    "            \n",
    "        # print(\"\\n--- Text Cleaning Steps ---\")\n",
    "        # print(f\"Original text: {text}\")\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        # print(f\"After lowercase: {text}\")\n",
    "        \n",
    "        # Remove special characters and extra spaces\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # print(f\"After removing special chars: {text}\")\n",
    "        \n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # print(f\"After normalizing spaces: {text}\")\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def build_vocabulary(self, texts):\n",
    "        \"\"\"Build vocabulary from list of texts\"\"\"\n",
    "        print(\"\\n=== Building Vocabulary ===\")\n",
    "        print(f\"Processing {len(texts)} texts\")\n",
    "        \n",
    "        word_counts = Counter()\n",
    "        for i, text in enumerate(texts):\n",
    "            cleaned_text = self.clean_text(text)\n",
    "            words = cleaned_text.split()\n",
    "            word_counts.update(words)\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(f\"Processed {i} texts...\")\n",
    "        \n",
    "        print(\"\\n--- Vocabulary Statistics ---\")\n",
    "        print(f\"Total unique words: {len(word_counts)}\")\n",
    "        print(\"Most common 10 words:\")\n",
    "        for word, count in word_counts.most_common(10):\n",
    "            print(f\"{word}: {count}\")\n",
    "        \n",
    "        # Keep most common words\n",
    "        vocab_words = ['<PAD>', '<UNK>'] + [word for word, _ in \n",
    "                      word_counts.most_common(self.max_vocab_size - 2)]\n",
    "        \n",
    "        # Create word to index mappings\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(vocab_words)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "        \n",
    "        print(f\"\\nFinal vocabulary size: {self.vocab_size}\")  # Keep this print statement\n",
    "        print(\"Sample word indices:\")\n",
    "        for word in list(self.word2idx.keys())[:5]:\n",
    "            print(f\"{word}: {self.word2idx[word]}\")\n",
    "    \n",
    "    def encode_text(self, text):\n",
    "        \"\"\"Convert text to sequence of indices\"\"\"\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        words = cleaned_text.split()\n",
    "        \n",
    "        # print(\"\\n--- Encoding Text ---\")\n",
    "        # print(f\"Cleaned text: {cleaned_text}\")\n",
    "        # print(f\"Number of words: {len(words)}\")\n",
    "        \n",
    "        # Truncate or pad sequence\n",
    "        if len(words) > self.max_seq_length:\n",
    "            # print(f\"Truncating sequence from {len(words)} to {self.max_seq_length}\")\n",
    "            words = words[:self.max_seq_length]\n",
    "        else:\n",
    "            padding_length = self.max_seq_length - len(words)\n",
    "            # print(f\"Adding {padding_length} padding tokens\")\n",
    "            words = words + ['<PAD>'] * padding_length\n",
    "            \n",
    "        # Convert words to indices\n",
    "        indices = [self.word2idx.get(word, self.word2idx['<UNK>']) \n",
    "                  for word in words]\n",
    "        \n",
    "        # print(\"First 10 indices:\", indices[:10])\n",
    "        return indices\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, preprocessor):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.preprocessor = preprocessor\n",
    "        \n",
    "        print(f\"Created dataset with {len(texts)} samples\")  # Keep this print statement\n",
    "        # print(f\"Label distribution: {Counter(labels)}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # print(f\"\\n--- Processing item {idx} ---\")\n",
    "        # print(f\"Original text: {text[:50]}...\")\n",
    "        \n",
    "        # Convert text to tensor\n",
    "        encoded_text = self.preprocessor.encode_text(text)\n",
    "        text_tensor = torch.tensor(encoded_text, dtype=torch.long)\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        # print(f\"Text tensor shape: {text_tensor.shape}\")\n",
    "        # print(f\"Label: {label}\")\n",
    "        \n",
    "        return text_tensor, label_tensor\n",
    "\n",
    "def prepare_data(file_path, preprocessor, batch_size=32, text_column='text', label_column='label'):\n",
    "    \"\"\"Prepare data for training using pandas\"\"\"\n",
    "    print(\"\\n=== Data Preparation Started ===\")  # Keep this print statement\n",
    "    \n",
    "    # Read data using pandas\n",
    "    try:\n",
    "        # First, try reading as CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Successfully read CSV file\")\n",
    "    except:\n",
    "        try:\n",
    "            # If CSV fails, try reading as Excel\n",
    "            df = pd.read_excel(file_path)\n",
    "            print(\"Successfully read Excel file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Display basic dataset information\n",
    "    print(\"\\n=== Dataset Information ===\")\n",
    "    print(df.info())\n",
    "    print(\"\\n=== Value Counts for Labels ===\")\n",
    "    print(df[label_column].value_counts())\n",
    "    \n",
    "    # Basic data cleaning\n",
    "    # Remove any rows with NaN in text or label columns\n",
    "    df = df.dropna(subset=[text_column, label_column])\n",
    "    \n",
    "    # Convert text and labels to lists\n",
    "    texts = df[text_column].tolist()\n",
    "    labels = df[label_column].tolist()\n",
    "    \n",
    "    print(f\"Loaded {len(texts)} samples\")  # Keep this print statement\n",
    "    \n",
    "    # Build vocabulary\n",
    "    preprocessor.build_vocabulary(texts)\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = TextDataset(texts, labels, preprocessor)\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print(f\"Created DataLoader with batch size {batch_size}\")  # Keep this print statement\n",
    "    \n",
    "    # Optional: Display sample of processed data\n",
    "    print(\"\\n=== Sample of Processed Data ===\")\n",
    "    sample_idx = np.random.randint(0, len(dataset), 3)\n",
    "    for idx in sample_idx:\n",
    "        text_tensor, label_tensor = dataset[idx]\n",
    "        print(f\"\\nSample {idx}:\")\n",
    "        print(f\"Original text: {texts[idx][:100]}...\")\n",
    "        print(f\"Label: {labels[idx]}\")\n",
    "        print(f\"Tensor shape: {text_tensor.shape}\")\n",
    "    \n",
    "    return dataloader, preprocessor.vocab_size, df\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize preprocessor\n",
    "    preprocessor = TextPreprocessor()\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"\\n=== Starting Data Processing ===\")  # Keep this print statement\n",
    "    \n",
    "    # Assuming the CSV has 'text' and 'label' columns - adjust as needed\n",
    "    dataloader, vocab_size, df = prepare_data('train.csv', \n",
    "                                            preprocessor,\n",
    "                                            text_column='text',  # Change to your text column name\n",
    "                                            label_column='label')  # Change to your label column name\n",
    "    \n",
    "    if dataloader is not None:\n",
    "        # Print some statistics\n",
    "        print(f\"Vocabulary size: {vocab_size}\")  # Keep this print statement\n",
    "        print(f\"Number of batches: {len(dataloader)}\")  # Keep this print statement\n",
    "        \n",
    "        # Example of accessing a batch\n",
    "        for batch_texts, batch_labels in dataloader:\n",
    "            print(f\"Batch shape: {batch_texts.shape}\")  # Keep this print statement\n",
    "            print(f\"Labels shape: {batch_labels.shape}\")  # Keep this print statement\n",
    "            # print(\"Sample sequence:\", batch_texts[0][:10])\n",
    "            # print(\"Sample label:\", batch_labels[0])\n",
    "            break\n",
    "\n",
    "    # #Optional: Data distribution visualization\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # df['label'].value_counts().plot(kind='bar')\n",
    "    # plt.title('Label Distribution')\n",
    "    # plt.xlabel('Label')\n",
    "    # plt.ylabel('Count')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "SelfAttentionClassifier(\n",
      "  (embedding): Embedding(10000, 512)\n",
      "  (pos_encoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder_layers): ModuleList(\n",
      "    (0-5): 6 x TransformerEncoderLayer(\n",
      "      (self_attn): MultiHeadAttention(\n",
      "        (q_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (k_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (v_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (out_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters: 24,166,146\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of Multi-Head Attention as described in Section 3.2.2 of \"Attention Is All You Need\"\n",
    "    Multi-head attention allows the model to jointly attend to information from different representation \n",
    "    subspaces at different positions.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model  # Model's dimension\n",
    "        self.num_heads = num_heads  # Number of attention heads\n",
    "        self.d_k = d_model // num_heads  # Dimension of each head's key/query\n",
    "        \n",
    "        # Linear projections for Q, K, V, and output as per Section 3.2.2\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def attention(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        Scaled Dot-Product Attention as defined in Section 3.2.1\n",
    "        attention(Q,K,V) = softmax(QK^T/sqrt(d_k))V\n",
    "        The scaling factor of sqrt(d_k) prevents softmax from having extremely small gradients\n",
    "        \"\"\"\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn_probs = F.softmax(scores, dim=-1)\n",
    "        attn_probs = self.dropout(attn_probs)\n",
    "        \n",
    "        return torch.matmul(attn_probs, v), attn_probs\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size(0)\n",
    "        \n",
    "        # Linear projections and split into heads\n",
    "        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Apply attention on all the projected vectors in batch\n",
    "        x, attn_probs = self.attention(q, k, v, mask)\n",
    "        \n",
    "        # Concatenate and apply final linear layer\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        return self.out_linear(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements positional encoding as described in Section 3.5\n",
    "    Adds positional information to the input embeddings to provide sequence order information,\n",
    "    since the attention mechanism itself is permutation-invariant\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_seq_length=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Create positional encoding matrix\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[:, :x.size(1)])\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single layer of the Transformer encoder as described in Section 3.1\n",
    "    Combines multi-head self-attention with position-wise feed-forward networks\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        \n",
    "        # Position-wise Feed-Forward Networks\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        \n",
    "        # Layer Normalization and Dropout\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Self-attention with residual connection and layer norm\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward with residual connection and layer norm\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class SelfAttentionClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete self-attention model for text classification\n",
    "    Combines token embeddings, positional encoding, transformer encoder layers,\n",
    "    and a classification head\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model=512, num_heads=8, num_layers=6, \n",
    "                 num_classes=2, max_seq_length=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_seq_length, dropout)\n",
    "        \n",
    "        # Stack of Transformer Encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model, num_heads, d_model * 4, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize parameters with Xavier/Glorot initialization\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # Token embeddings and positional encoding\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        # Apply transformer encoder layers\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, mask)\n",
    "        \n",
    "        # Global average pooling over sequence length\n",
    "        x = x.mean(dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        return self.classifier(x)\n",
    "\n",
    "def create_attention_mask(seq_len):\n",
    "    \"\"\"\n",
    "    Creates attention mask for self-attention as described in Section 3.2.3\n",
    "    Prevents positions from attending to subsequent positions\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "    return ~mask\n",
    "\n",
    "# Training utilities\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Training loop for one epoch\n",
    "    Implements the training procedure with attention mechanisms\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (texts, labels) in enumerate(dataloader):\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        \n",
    "        # Create attention mask\n",
    "        mask = create_attention_mask(texts.size(1)).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts, mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Model parameters\n",
    "    VOCAB_SIZE = 10000\n",
    "    D_MODEL = 512\n",
    "    NUM_HEADS = 8\n",
    "    NUM_LAYERS = 6\n",
    "    NUM_CLASSES = 2\n",
    "    MAX_SEQ_LENGTH = 512\n",
    "    DROPOUT = 0.1\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SelfAttentionClassifier(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    print(\"Model architecture:\")\n",
    "    print(model)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nTotal parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings...\n",
      "Creating 2D visualization...\n",
      "Creating 3D visualization...\n",
      "\n",
      "Words most similar to '<PAD>':\n",
      "has: 0.414\n",
      "life: 0.417\n",
      "links: 0.417\n",
      "four: 0.419\n",
      "sure: 0.419\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "<PAD>"
          ],
          [
           "<UNK>"
          ],
          [
           "the"
          ],
          [
           "to"
          ],
          [
           "of"
          ],
          [
           "and"
          ],
          [
           "a"
          ],
          [
           "you"
          ],
          [
           "i"
          ],
          [
           "is"
          ],
          [
           "that"
          ],
          [
           "in"
          ],
          [
           "it"
          ],
          [
           "for"
          ],
          [
           "this"
          ],
          [
           "not"
          ],
          [
           "on"
          ],
          [
           "be"
          ],
          [
           "as"
          ],
          [
           "have"
          ],
          [
           "are"
          ],
          [
           "your"
          ],
          [
           "with"
          ],
          [
           "if"
          ],
          [
           "article"
          ],
          [
           "was"
          ],
          [
           "or"
          ],
          [
           "but"
          ],
          [
           "page"
          ],
          [
           "my"
          ],
          [
           "an"
          ],
          [
           "from"
          ],
          [
           "by"
          ],
          [
           "do"
          ],
          [
           "at"
          ],
          [
           "about"
          ],
          [
           "me"
          ],
          [
           "so"
          ],
          [
           "wikipedia"
          ],
          [
           "can"
          ],
          [
           "what"
          ],
          [
           "there"
          ],
          [
           "talk"
          ],
          [
           "all"
          ],
          [
           "has"
          ],
          [
           "will"
          ],
          [
           "please"
          ],
          [
           "would"
          ],
          [
           "its"
          ],
          [
           "no"
          ],
          [
           "one"
          ],
          [
           "just"
          ],
          [
           "like"
          ],
          [
           "they"
          ],
          [
           "he"
          ],
          [
           "dont"
          ],
          [
           "which"
          ],
          [
           "any"
          ],
          [
           "been"
          ],
          [
           "should"
          ],
          [
           "more"
          ],
          [
           "we"
          ],
          [
           "some"
          ],
          [
           "other"
          ],
          [
           "who"
          ],
          [
           "see"
          ],
          [
           "here"
          ],
          [
           "also"
          ],
          [
           "his"
          ],
          [
           "think"
          ],
          [
           "im"
          ],
          [
           "because"
          ],
          [
           "know"
          ],
          [
           "how"
          ],
          [
           "am"
          ],
          [
           "people"
          ],
          [
           "why"
          ],
          [
           "edit"
          ],
          [
           "articles"
          ],
          [
           "only"
          ],
          [
           "up"
          ],
          [
           "out"
          ],
          [
           "when"
          ],
          [
           "were"
          ],
          [
           "use"
          ],
          [
           "then"
          ],
          [
           "may"
          ],
          [
           "time"
          ],
          [
           "did"
          ],
          [
           "them"
          ],
          [
           "now"
          ],
          [
           "being"
          ],
          [
           "their"
          ],
          [
           "than"
          ],
          [
           "thanks"
          ],
          [
           "even"
          ],
          [
           "get"
          ],
          [
           "make"
          ],
          [
           "good"
          ],
          [
           "had"
          ],
          [
           "very"
          ],
          [
           "information"
          ],
          [
           "does"
          ],
          [
           "could"
          ],
          [
           "well"
          ],
          [
           "want"
          ],
          [
           "such"
          ],
          [
           "sources"
          ],
          [
           "way"
          ],
          [
           "name"
          ],
          [
           "these"
          ],
          [
           "deletion"
          ],
          [
           "pages"
          ],
          [
           "first"
          ],
          [
           "help"
          ],
          [
           "new"
          ],
          [
           "editing"
          ],
          [
           "source"
          ],
          [
           "go"
          ],
          [
           "need"
          ],
          [
           "say"
          ],
          [
           "section"
          ],
          [
           "edits"
          ],
          [
           "again"
          ],
          [
           "thank"
          ],
          [
           "where"
          ],
          [
           "user"
          ],
          [
           "made"
          ],
          [
           "many"
          ],
          [
           "much"
          ],
          [
           "really"
          ],
          [
           "used"
          ],
          [
           "most"
          ],
          [
           "discussion"
          ],
          [
           "ive"
          ],
          [
           "find"
          ],
          [
           "same"
          ],
          [
           "deleted"
          ],
          [
           "into"
          ],
          [
           "fuck"
          ],
          [
           "work"
          ],
          [
           "those"
          ],
          [
           "since"
          ],
          [
           "before"
          ],
          [
           "after"
          ],
          [
           "point"
          ],
          [
           "add"
          ],
          [
           "look"
          ],
          [
           "right"
          ],
          [
           "read"
          ],
          [
           "image"
          ],
          [
           "take"
          ],
          [
           "still"
          ],
          [
           "over"
          ],
          [
           "someone"
          ],
          [
           "him"
          ],
          [
           "two"
          ],
          [
           "back"
          ],
          [
           "too"
          ],
          [
           "fact"
          ],
          [
           "link"
          ],
          [
           "said"
          ],
          [
           "own"
          ],
          [
           "youre"
          ],
          [
           "something"
          ],
          [
           "going"
          ],
          [
           "blocked"
          ],
          [
           "list"
          ],
          [
           "stop"
          ],
          [
           "without"
          ],
          [
           "content"
          ],
          [
           "hi"
          ],
          [
           "thats"
          ],
          [
           "editors"
          ],
          [
           "under"
          ],
          [
           "our"
          ],
          [
           "block"
          ],
          [
           "us"
          ],
          [
           "utc"
          ],
          [
           "added"
          ],
          [
           "doesnt"
          ],
          [
           "history"
          ],
          [
           "another"
          ],
          [
           "removed"
          ],
          [
           "might"
          ],
          [
           "welcome"
          ],
          [
           "note"
          ],
          [
           "however"
          ],
          [
           "sure"
          ],
          [
           "place"
          ],
          [
           "never"
          ],
          [
           "done"
          ],
          [
           "her"
          ],
          [
           "case"
          ],
          [
           "put"
          ],
          [
           "cant"
          ],
          [
           "personal"
          ],
          [
           "seems"
          ],
          [
           "better"
          ],
          [
           "reason"
          ],
          [
           "using"
          ],
          [
           "yourself"
          ],
          [
           "actually"
          ],
          [
           "ask"
          ],
          [
           "comment"
          ],
          [
           "vandalism"
          ],
          [
           "while"
          ],
          [
           "feel"
          ],
          [
           "question"
          ],
          [
           "anything"
          ],
          [
           "believe"
          ],
          [
           "person"
          ],
          [
           "didnt"
          ],
          [
           "links"
          ],
          [
           "things"
          ],
          [
           "both"
          ],
          [
           "ill"
          ],
          [
           "best"
          ],
          [
           "comments"
          ],
          [
           "part"
          ],
          [
           "she"
          ],
          [
           "hope"
          ],
          [
           "policy"
          ],
          [
           "against"
          ],
          [
           "off"
          ],
          [
           "keep"
          ],
          [
           "already"
          ],
          [
           "wiki"
          ],
          [
           "free"
          ],
          [
           "thing"
          ],
          [
           "nothing"
          ],
          [
           "change"
          ],
          [
           "wrong"
          ],
          [
           "though"
          ],
          [
           "problem"
          ],
          [
           "remove"
          ],
          [
           "little"
          ],
          [
           "subject"
          ],
          [
           "others"
          ],
          [
           "tag"
          ],
          [
           "trying"
          ],
          [
           "copyright"
          ],
          [
           "must"
          ],
          [
           "understand"
          ],
          [
           "above"
          ],
          [
           "few"
          ],
          [
           "anyone"
          ],
          [
           "speedy"
          ],
          [
           "last"
          ],
          [
           "issue"
          ],
          [
           "give"
          ],
          [
           "2"
          ],
          [
           "questions"
          ],
          [
           "years"
          ],
          [
           "agree"
          ],
          [
           "rather"
          ],
          [
           "let"
          ],
          [
           "different"
          ],
          [
           "editor"
          ],
          [
           "isnt"
          ],
          [
           "long"
          ],
          [
           "reliable"
          ],
          [
           "world"
          ],
          [
           "making"
          ],
          [
           "come"
          ],
          [
           "sorry"
          ],
          [
           "reference"
          ],
          [
           "mean"
          ],
          [
           "try"
          ],
          [
           "references"
          ],
          [
           "continue"
          ],
          [
           "found"
          ],
          [
           "doing"
          ],
          [
           "text"
          ],
          [
           "great"
          ],
          [
           "leave"
          ],
          [
           "says"
          ],
          [
           "got"
          ],
          [
           "probably"
          ],
          [
           "english"
          ],
          [
           "1"
          ],
          [
           "original"
          ],
          [
           "every"
          ],
          [
           "simply"
          ],
          [
           "word"
          ],
          [
           "users"
          ],
          [
           "hello"
          ],
          [
           "fair"
          ],
          [
           "either"
          ],
          [
           "check"
          ],
          [
           "least"
          ],
          [
           "adding"
          ],
          [
           "ip"
          ],
          [
           "show"
          ],
          [
           "state"
          ],
          [
           "site"
          ],
          [
           "else"
          ],
          [
           "delete"
          ],
          [
           "consensus"
          ],
          [
           "enough"
          ],
          [
           "request"
          ],
          [
           "opinion"
          ],
          [
           "far"
          ],
          [
           "created"
          ],
          [
           "around"
          ],
          [
           "life"
          ],
          [
           "day"
          ],
          [
           "between"
          ],
          [
           "through"
          ],
          [
           "example"
          ],
          [
           "view"
          ],
          [
           "reverted"
          ],
          [
           "yes"
          ],
          [
           "yet"
          ],
          [
           "id"
          ],
          [
           "etc"
          ],
          [
           "contributions"
          ],
          [
           "matter"
          ],
          [
           "shit"
          ],
          [
           "war"
          ],
          [
           "u"
          ],
          [
           "notable"
          ],
          [
           "given"
          ],
          [
           "thought"
          ],
          [
           "material"
          ],
          [
           "book"
          ],
          [
           "admin"
          ],
          [
           "write"
          ],
          [
           "down"
          ],
          [
           "post"
          ],
          [
           "account"
          ],
          [
           "having"
          ],
          [
           "clearly"
          ],
          [
           "encyclopedia"
          ],
          [
           "support"
          ],
          [
           "lot"
          ],
          [
           "real"
          ],
          [
           "bad"
          ],
          [
           "message"
          ],
          [
           "needs"
          ],
          [
           "images"
          ],
          [
           "tell"
          ],
          [
           "seem"
          ],
          [
           "called"
          ],
          [
           "evidence"
          ],
          [
           "maybe"
          ],
          [
           "instead"
          ],
          [
           "ever"
          ],
          [
           "3"
          ],
          [
           "correct"
          ],
          [
           "saying"
          ],
          [
           "clear"
          ],
          [
           "always"
          ],
          [
           "number"
          ],
          [
           "important"
          ],
          [
           "further"
          ],
          [
           "quite"
          ],
          [
           "perhaps"
          ],
          [
           "old"
          ],
          [
           "true"
          ],
          [
           "hate"
          ],
          [
           "until"
          ],
          [
           "states"
          ],
          [
           "whether"
          ],
          [
           "consider"
          ],
          [
           "written"
          ],
          [
           "claim"
          ],
          [
           "language"
          ],
          [
           "media"
          ],
          [
           "bit"
          ],
          [
           "once"
          ],
          [
           "guidelines"
          ],
          [
           "term"
          ],
          [
           "version"
          ],
          [
           "criteria"
          ],
          [
           "research"
          ],
          [
           "nigger"
          ],
          [
           "times"
          ],
          [
           "theres"
          ],
          [
           "website"
          ],
          [
           "fucking"
          ],
          [
           "getting"
          ],
          [
           "review"
          ],
          [
           "mention"
          ],
          [
           "pov"
          ],
          [
           "oh"
          ],
          [
           "makes"
          ],
          [
           "several"
          ],
          [
           "revert"
          ],
          [
           "considered"
          ],
          [
           "changes"
          ],
          [
           "words"
          ],
          [
           "cannot"
          ],
          [
           "idea"
          ],
          [
           "title"
          ],
          [
           "suck"
          ],
          [
           "address"
          ],
          [
           "notice"
          ],
          [
           "based"
          ],
          [
           "top"
          ],
          [
           "current"
          ],
          [
           "following"
          ],
          [
           "each"
          ],
          [
           "listed"
          ],
          [
           "means"
          ],
          [
           "group"
          ],
          [
           "possible"
          ],
          [
           "facts"
          ],
          [
           "regarding"
          ],
          [
           "care"
          ],
          [
           "rules"
          ],
          [
           "second"
          ],
          [
           "main"
          ],
          [
           "template"
          ],
          [
           "general"
          ],
          [
           "mentioned"
          ],
          [
           "year"
          ],
          [
           "attack"
          ],
          [
           "whole"
          ],
          [
           "course"
          ],
          [
           "kind"
          ],
          [
           "statement"
          ],
          [
           "left"
          ],
          [
           "hey"
          ],
          [
           "date"
          ],
          [
           "include"
          ],
          [
           "seen"
          ],
          [
           "three"
          ],
          [
           "start"
          ],
          [
           "wikipedias"
          ],
          [
           "issues"
          ],
          [
           "ass"
          ],
          [
           "ok"
          ],
          [
           "end"
          ],
          [
           "call"
          ],
          [
           "less"
          ],
          [
           "topic"
          ],
          [
           "gay"
          ],
          [
           "suggest"
          ],
          [
           "man"
          ],
          [
           "including"
          ],
          [
           "happy"
          ],
          [
           "sense"
          ],
          [
           "big"
          ],
          [
           "create"
          ],
          [
           "provide"
          ],
          [
           "days"
          ],
          [
           "myself"
          ],
          [
           "american"
          ],
          [
           "redirect"
          ],
          [
           "known"
          ],
          [
           "appropriate"
          ],
          [
           "sentence"
          ],
          [
           "move"
          ],
          [
           "love"
          ],
          [
           "changed"
          ],
          [
           "notability"
          ],
          [
           "explain"
          ],
          [
           "started"
          ],
          [
           "included"
          ],
          [
           "project"
          ],
          [
           "removing"
          ],
          [
           "mind"
          ],
          [
           "anyway"
          ],
          [
           "info"
          ],
          [
           "school"
          ],
          [
           "2005"
          ],
          [
           "next"
          ],
          [
           "looking"
          ],
          [
           "although"
          ],
          [
           "wont"
          ],
          [
           "picture"
          ],
          [
           "four"
          ],
          [
           "relevant"
          ],
          [
           "die"
          ],
          [
           "style"
          ],
          [
           "answer"
          ],
          [
           "sign"
          ],
          [
           "away"
          ],
          [
           "per"
          ],
          [
           "youve"
          ],
          [
           "warning"
          ],
          [
           "order"
          ],
          [
           "interest"
          ],
          [
           "recent"
          ],
          [
           "community"
          ],
          [
           "summary"
          ],
          [
           "later"
          ],
          [
           "lol"
          ],
          [
           "claims"
          ],
          [
           "discuss"
          ],
          [
           "currently"
          ],
          [
           "interested"
          ],
          [
           "attacks"
          ],
          [
           "policies"
          ],
          [
           "especially"
          ],
          [
           "wish"
          ],
          [
           "wrote"
          ],
          [
           "able"
          ],
          [
           "specific"
          ]
         ],
         "hovertemplate": "x=%{x}<br>y=%{y}<br>word=%{customdata[0]}<br>cluster=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           6,
           2,
           6,
           6,
           3,
           0,
           3,
           7,
           0,
           2,
           3,
           1,
           0,
           0,
           6,
           3,
           6,
           6,
           6,
           3,
           6,
           3,
           3,
           7,
           2,
           3,
           1,
           2,
           6,
           0,
           7,
           6,
           4,
           2,
           5,
           7,
           6,
           2,
           5,
           2,
           0,
           6,
           6,
           0,
           0,
           6,
           5,
           6,
           2,
           6,
           3,
           0,
           6,
           0,
           6,
           6,
           5,
           6,
           6,
           0,
           3,
           6,
           2,
           5,
           0,
           0,
           2,
           0,
           0,
           6,
           7,
           7,
           2,
           3,
           6,
           4,
           6,
           1,
           2,
           6,
           6,
           3,
           5,
           1,
           3,
           2,
           2,
           6,
           6,
           6,
           6,
           0,
           2,
           4,
           2,
           0,
           6,
           7,
           7,
           6,
           7,
           6,
           6,
           6,
           2,
           7,
           7,
           1,
           2,
           2,
           6,
           3,
           7,
           3,
           6,
           2,
           1,
           7,
           0,
           7,
           6,
           0,
           6,
           0,
           0,
           6,
           0,
           3,
           0,
           2,
           6,
           0,
           2,
           6,
           2,
           6,
           1,
           3,
           3,
           6,
           3,
           3,
           6,
           0,
           5,
           2,
           3,
           6,
           2,
           6,
           3,
           2,
           5,
           2,
           5,
           6,
           3,
           4,
           6,
           2,
           6,
           6,
           3,
           0,
           6,
           6,
           6,
           7,
           0,
           0,
           6,
           0,
           3,
           1,
           2,
           3,
           6,
           6,
           6,
           6,
           6,
           0,
           6,
           6,
           5,
           6,
           4,
           0,
           6,
           5,
           0,
           0,
           0,
           1,
           0,
           3,
           5,
           3,
           5,
           6,
           4,
           2,
           6,
           6,
           2,
           6,
           2,
           6,
           7,
           7,
           5,
           6,
           6,
           0,
           6,
           4,
           0,
           2,
           0,
           2,
           4,
           6,
           2,
           0,
           2,
           5,
           2,
           6,
           0,
           7,
           4,
           2,
           0,
           6,
           6,
           6,
           5,
           4,
           6,
           3,
           6,
           0,
           6,
           2,
           6,
           0,
           0,
           0,
           6,
           6,
           6,
           7,
           6,
           0,
           6,
           2,
           3,
           6,
           0,
           7,
           0,
           0,
           3,
           5,
           5,
           7,
           6,
           3,
           0,
           3,
           7,
           6,
           6,
           3,
           6,
           1,
           0,
           6,
           0,
           6,
           6,
           6,
           5,
           3,
           6,
           3,
           6,
           6,
           0,
           6,
           0,
           6,
           7,
           2,
           2,
           3,
           7,
           6,
           3,
           0,
           1,
           0,
           5,
           2,
           7,
           3,
           0,
           3,
           5,
           3,
           5,
           0,
           3,
           4,
           2,
           1,
           0,
           6,
           6,
           6,
           5,
           6,
           0,
           0,
           0,
           0,
           0,
           2,
           3,
           0,
           6,
           0,
           2,
           5,
           4,
           2,
           2,
           5,
           0,
           6,
           6,
           0,
           2,
           6,
           4,
           1,
           6,
           5,
           2,
           6,
           6,
           6,
           2,
           3,
           6,
           6,
           0,
           3,
           0,
           0,
           0,
           2,
           2,
           1,
           0,
           0,
           3,
           0,
           7,
           6,
           2,
           2,
           7,
           4,
           0,
           5,
           0,
           0,
           0,
           2,
           2,
           2,
           5,
           6,
           7,
           2,
           6,
           6,
           4,
           0,
           6,
           6,
           6,
           7,
           7,
           4,
           6,
           3,
           3,
           6,
           0,
           1,
           2,
           5,
           6,
           3,
           6,
           3,
           6,
           6,
           6,
           6,
           6,
           6,
           2,
           5,
           6,
           0,
           6,
           2,
           6,
           3,
           0,
           2,
           2,
           1,
           0,
           0,
           6,
           4,
           5,
           4,
           0,
           5,
           6,
           5,
           6,
           3,
           5,
           6,
           4,
           0,
           3,
           4,
           1,
           2,
           4,
           6,
           6,
           0,
           5,
           6,
           3,
           0,
           6,
           4,
           0,
           6,
           6,
           1,
           2,
           2,
           4,
           2,
           2,
           6,
           6,
           6,
           4,
           0,
           6,
           0,
           6,
           0,
           5,
           2,
           6,
           4,
           2,
           0,
           5,
           6,
           4,
           5,
           4,
           7,
           7,
           6,
           4,
           6,
           6,
           0,
           0,
           7,
           3,
           3,
           2,
           2,
           0,
           5
          ],
          "coloraxis": "coloraxis",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          "<PAD>",
          "<UNK>",
          "the",
          "to",
          "of",
          "and",
          "a",
          "you",
          "i",
          "is",
          "that",
          "in",
          "it",
          "for",
          "this",
          "not",
          "on",
          "be",
          "as",
          "have",
          "are",
          "your",
          "with",
          "if",
          "article",
          "was",
          "or",
          "but",
          "page",
          "my",
          "an",
          "from",
          "by",
          "do",
          "at",
          "about",
          "me",
          "so",
          "wikipedia",
          "can",
          "what",
          "there",
          "talk",
          "all",
          "has",
          "will",
          "please",
          "would",
          "its",
          "no",
          "one",
          "just",
          "like",
          "they",
          "he",
          "dont",
          "which",
          "any",
          "been",
          "should",
          "more",
          "we",
          "some",
          "other",
          "who",
          "see",
          "here",
          "also",
          "his",
          "think",
          "im",
          "because",
          "know",
          "how",
          "am",
          "people",
          "why",
          "edit",
          "articles",
          "only",
          "up",
          "out",
          "when",
          "were",
          "use",
          "then",
          "may",
          "time",
          "did",
          "them",
          "now",
          "being",
          "their",
          "than",
          "thanks",
          "even",
          "get",
          "make",
          "good",
          "had",
          "very",
          "information",
          "does",
          "could",
          "well",
          "want",
          "such",
          "sources",
          "way",
          "name",
          "these",
          "deletion",
          "pages",
          "first",
          "help",
          "new",
          "editing",
          "source",
          "go",
          "need",
          "say",
          "section",
          "edits",
          "again",
          "thank",
          "where",
          "user",
          "made",
          "many",
          "much",
          "really",
          "used",
          "most",
          "discussion",
          "ive",
          "find",
          "same",
          "deleted",
          "into",
          "fuck",
          "work",
          "those",
          "since",
          "before",
          "after",
          "point",
          "add",
          "look",
          "right",
          "read",
          "image",
          "take",
          "still",
          "over",
          "someone",
          "him",
          "two",
          "back",
          "too",
          "fact",
          "link",
          "said",
          "own",
          "youre",
          "something",
          "going",
          "blocked",
          "list",
          "stop",
          "without",
          "content",
          "hi",
          "thats",
          "editors",
          "under",
          "our",
          "block",
          "us",
          "utc",
          "added",
          "doesnt",
          "history",
          "another",
          "removed",
          "might",
          "welcome",
          "note",
          "however",
          "sure",
          "place",
          "never",
          "done",
          "her",
          "case",
          "put",
          "cant",
          "personal",
          "seems",
          "better",
          "reason",
          "using",
          "yourself",
          "actually",
          "ask",
          "comment",
          "vandalism",
          "while",
          "feel",
          "question",
          "anything",
          "believe",
          "person",
          "didnt",
          "links",
          "things",
          "both",
          "ill",
          "best",
          "comments",
          "part",
          "she",
          "hope",
          "policy",
          "against",
          "off",
          "keep",
          "already",
          "wiki",
          "free",
          "thing",
          "nothing",
          "change",
          "wrong",
          "though",
          "problem",
          "remove",
          "little",
          "subject",
          "others",
          "tag",
          "trying",
          "copyright",
          "must",
          "understand",
          "above",
          "few",
          "anyone",
          "speedy",
          "last",
          "issue",
          "give",
          "2",
          "questions",
          "years",
          "agree",
          "rather",
          "let",
          "different",
          "editor",
          "isnt",
          "long",
          "reliable",
          "world",
          "making",
          "come",
          "sorry",
          "reference",
          "mean",
          "try",
          "references",
          "continue",
          "found",
          "doing",
          "text",
          "great",
          "leave",
          "says",
          "got",
          "probably",
          "english",
          "1",
          "original",
          "every",
          "simply",
          "word",
          "users",
          "hello",
          "fair",
          "either",
          "check",
          "least",
          "adding",
          "ip",
          "show",
          "state",
          "site",
          "else",
          "delete",
          "consensus",
          "enough",
          "request",
          "opinion",
          "far",
          "created",
          "around",
          "life",
          "day",
          "between",
          "through",
          "example",
          "view",
          "reverted",
          "yes",
          "yet",
          "id",
          "etc",
          "contributions",
          "matter",
          "shit",
          "war",
          "u",
          "notable",
          "given",
          "thought",
          "material",
          "book",
          "admin",
          "write",
          "down",
          "post",
          "account",
          "having",
          "clearly",
          "encyclopedia",
          "support",
          "lot",
          "real",
          "bad",
          "message",
          "needs",
          "images",
          "tell",
          "seem",
          "called",
          "evidence",
          "maybe",
          "instead",
          "ever",
          "3",
          "correct",
          "saying",
          "clear",
          "always",
          "number",
          "important",
          "further",
          "quite",
          "perhaps",
          "old",
          "true",
          "hate",
          "until",
          "states",
          "whether",
          "consider",
          "written",
          "claim",
          "language",
          "media",
          "bit",
          "once",
          "guidelines",
          "term",
          "version",
          "criteria",
          "research",
          "nigger",
          "times",
          "theres",
          "website",
          "fucking",
          "getting",
          "review",
          "mention",
          "pov",
          "oh",
          "makes",
          "several",
          "revert",
          "considered",
          "changes",
          "words",
          "cannot",
          "idea",
          "title",
          "suck",
          "address",
          "notice",
          "based",
          "top",
          "current",
          "following",
          "each",
          "listed",
          "means",
          "group",
          "possible",
          "facts",
          "regarding",
          "care",
          "rules",
          "second",
          "main",
          "template",
          "general",
          "mentioned",
          "year",
          "attack",
          "whole",
          "course",
          "kind",
          "statement",
          "left",
          "hey",
          "date",
          "include",
          "seen",
          "three",
          "start",
          "wikipedias",
          "issues",
          "ass",
          "ok",
          "end",
          "call",
          "less",
          "topic",
          "gay",
          "suggest",
          "man",
          "including",
          "happy",
          "sense",
          "big",
          "create",
          "provide",
          "days",
          "myself",
          "american",
          "redirect",
          "known",
          "appropriate",
          "sentence",
          "move",
          "love",
          "changed",
          "notability",
          "explain",
          "started",
          "included",
          "project",
          "removing",
          "mind",
          "anyway",
          "info",
          "school",
          "2005",
          "next",
          "looking",
          "although",
          "wont",
          "picture",
          "four",
          "relevant",
          "die",
          "style",
          "answer",
          "sign",
          "away",
          "per",
          "youve",
          "warning",
          "order",
          "interest",
          "recent",
          "community",
          "summary",
          "later",
          "lol",
          "claims",
          "discuss",
          "currently",
          "interested",
          "attacks",
          "policies",
          "especially",
          "wish",
          "wrote",
          "able",
          "specific"
         ],
         "textfont": {
          "size": 10
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          9.743941,
          -2.4623468,
          -1.9735969,
          -5.303172,
          1.864763,
          3.1837845,
          7.1485357,
          -1.6774135,
          0.7918925,
          -6.0108585,
          2.0655549,
          7.1218762,
          2.3863847,
          -9.973798,
          4.7293344,
          -7.0665607,
          1.2027391,
          7.5666018,
          0.364232,
          1.1994339,
          -1.8031493,
          1.1459321,
          11.031658,
          4.5000677,
          11.544409,
          -1.4940568,
          0.03909239,
          -7.701654,
          -12.385145,
          3.7953858,
          1.8716003,
          12.004045,
          -1.3812553,
          3.9524248,
          -4.376346,
          0.0058983597,
          -5.218613,
          7.695851,
          7.8750267,
          -13.434433,
          3.1492217,
          -3.6197498,
          11.826214,
          -1.3122413,
          -4.2742996,
          -15.543977,
          0.87579733,
          -4.366799,
          13.610059,
          -0.41985562,
          -5.9282246,
          -13.583799,
          4.462903,
          0.161111,
          -13.189986,
          -4.661117,
          -2.65431,
          9.236449,
          -4.5133476,
          4.4797707,
          9.510152,
          1.3234406,
          -10.802937,
          9.526294,
          5.311127,
          -5.882237,
          3.6273077,
          -1.8205206,
          -4.3931437,
          6.380108,
          1.6064396,
          4.3116665,
          -11.100911,
          -3.3845575,
          7.0069404,
          6.3839135,
          -5.169836,
          -5.247964,
          7.8003607,
          -1.8274587,
          10.779276,
          -1.373829,
          10.996386,
          3.3993502,
          9.74228,
          14.643226,
          -1.3353213,
          6.5253496,
          -8.050177,
          -13.195297,
          1.1539621,
          1.0981596,
          8.459538,
          5.5171957,
          6.9990654,
          -9.11671,
          0.15475227,
          -5.36509,
          -9.844773,
          6.6531997,
          5.498906,
          -8.308646,
          8.851565,
          -1.6639328,
          11.12743,
          -8.124629,
          0.0701313,
          -13.127343,
          -5.0380344,
          -4.976584,
          -0.5315811,
          -6.517726,
          2.244858,
          -10.317035,
          -2.8674757,
          -4.233204,
          -3.6262507,
          10.093984,
          3.6228106,
          6.9403386,
          4.6913767,
          -3.6661496,
          -5.743855,
          -4.470184,
          13.357271,
          -0.28237975,
          -11.566108,
          1.7981335,
          4.945099,
          -2.3415139,
          -6.804214,
          -0.9708034,
          -14.100099,
          14.224247,
          1.8532993,
          -0.5307356,
          -6.4347434,
          5.4935513,
          -1.7390552,
          -3.8966591,
          1.6626863,
          -4.937631,
          -0.066732325,
          7.461007,
          -17.237309,
          2.8600538,
          8.253843,
          0.27172905,
          1.6229043,
          -9.852142,
          7.9244595,
          -3.2704616,
          -8.513881,
          6.7376633,
          -11.123221,
          -3.3153396,
          -3.5030208,
          -14.673373,
          -1.2610648,
          7.4670677,
          11.803174,
          8.6433935,
          -9.980887,
          13.530806,
          2.3970451,
          -10.873644,
          7.7980165,
          11.09243,
          -5.607294,
          -6.5641017,
          5.6328797,
          -3.4428074,
          -5.3410025,
          -7.459488,
          14.270986,
          -9.279846,
          11.671741,
          9.556023,
          9.7051935,
          4.7295556,
          -6.3936996,
          3.191615,
          7.0272684,
          -5.473621,
          2.2745507,
          7.4002852,
          15.456536,
          3.118103,
          1.1457537,
          5.2803626,
          7.8801603,
          -3.7210248,
          -15.524862,
          -9.167861,
          10.215835,
          4.573919,
          -2.7421403,
          -1.7939314,
          -1.9970044,
          6.1545563,
          -4.38975,
          -7.672282,
          8.707268,
          3.454833,
          -11.016694,
          -0.40969908,
          7.1901307,
          -2.6661081,
          -5.664375,
          -3.0566182,
          -8.118324,
          -11.476619,
          8.539954,
          2.3691764,
          10.5935755,
          -1.9343085,
          -5.632517,
          10.138178,
          -4.4238653,
          10.217251,
          -14.63076,
          -7.232299,
          9.334534,
          1.6653733,
          7.74368,
          -3.8513486,
          1.0916531,
          -7.584872,
          5.862895,
          -3.6207051,
          -9.437541,
          -6.517189,
          -3.5251389,
          -0.75428957,
          7.949349,
          1.7945846,
          2.611988,
          0.5481583,
          -1.094725,
          -2.0729942,
          14.143312,
          -0.24279211,
          -11.221925,
          8.871615,
          0.99735653,
          8.433619,
          -3.7319975,
          -2.9239423,
          -0.76505214,
          -1.1488837,
          -5.159014,
          3.036229,
          -8.912374,
          -3.9412389,
          -7.8446174,
          -0.8439585,
          -5.171623,
          11.65236,
          0.09860705,
          3.7214496,
          -8.577117,
          2.9676118,
          -2.1234062,
          -8.077104,
          -2.7736144,
          -4.174437,
          -2.4071755,
          4.6725726,
          0.57181525,
          0.1449534,
          2.896467,
          -2.9168081,
          5.1816096,
          -1.8860737,
          -0.04005865,
          5.081563,
          -2.9591763,
          7.940601,
          2.8364005,
          -4.7636867,
          13.821047,
          12.408014,
          -5.412075,
          -8.048365,
          6.586786,
          -7.4318886,
          2.5320632,
          4.752615,
          -5.510604,
          0.8835929,
          6.8759084,
          -5.0426197,
          -10.187898,
          9.714131,
          3.680782,
          0.43382818,
          5.306384,
          12.878478,
          2.8506079,
          -14.681352,
          -11.12771,
          10.747226,
          -0.3883042,
          15.449715,
          3.1233702,
          0.6036598,
          -3.897343,
          17.452301,
          -3.3026075,
          -5.832852,
          9.376775,
          3.4339707,
          1.5149314,
          5.3316307,
          10.178443,
          -6.1833663,
          -0.09996314,
          -11.516518,
          -3.6952546,
          -12.128641,
          -3.4761896,
          -12.251148,
          3.0995295,
          4.113173,
          5.8252263,
          7.1231656,
          -2.9358373,
          -13.683664,
          2.6993814,
          -4.422733,
          7.11779,
          -10.235494,
          11.755291,
          -10.441485,
          -2.0503297,
          -0.45641935,
          -10.803351,
          4.345881,
          -0.40281078,
          8.820367,
          0.8403328,
          -6.838904,
          6.2928305,
          0.028785922,
          -9.492281,
          1.5898527,
          -12.212441,
          -3.1649618,
          -8.26047,
          9.241625,
          0.22441055,
          11.932437,
          -0.59208816,
          -5.8980937,
          -4.7746897,
          4.6883473,
          -7.416333,
          -9.663917,
          -8.402765,
          0.45541635,
          10.658155,
          -5.2835064,
          -15.181027,
          -4.3501887,
          9.214744,
          4.475547,
          -7.863518,
          -10.298341,
          3.6944,
          -0.3487557,
          1.7595437,
          -11.128551,
          3.3746169,
          0.5788552,
          4.5883503,
          6.8208184,
          3.194581,
          -9.937945,
          6.156669,
          3.2037654,
          -13.209249,
          -11.231924,
          0.34876785,
          5.6412964,
          -2.542765,
          2.6740935,
          -12.523578,
          2.1386564,
          -2.046733,
          -11.222235,
          4.557741,
          2.0542307,
          7.5806446,
          -0.5190598,
          -7.11283,
          6.42347,
          -6.8174887,
          -1.555276,
          14.463674,
          12.302695,
          5.442489,
          13.198678,
          -14.131956,
          9.150894,
          -1.0343475,
          12.914538,
          -6.298871,
          5.511702,
          -8.268589,
          6.7858286,
          6.402321,
          2.3608892,
          9.966658,
          4.570767,
          16.554956,
          16.3871,
          3.8997793,
          0.5515335,
          -7.1025686,
          2.293885,
          7.600594,
          3.750639,
          9.043817,
          -2.734663,
          2.0091648,
          -3.4945114,
          4.035533,
          -5.349844,
          0.56764543,
          -5.562678,
          10.7887335,
          -8.482971,
          -0.7349674,
          -2.0034573,
          -1.9611852,
          -12.213857,
          1.5481184,
          -7.970222,
          -6.6521854,
          -3.2022228,
          -6.4582276,
          -13.577612,
          -6.775443,
          5.736648,
          12.513509,
          2.0758321,
          -4.504181,
          12.063607,
          4.830916,
          0.20867012,
          14.480852,
          -8.016803,
          5.1912417,
          4.384024,
          5.058829,
          -7.740403,
          9.212311,
          -14.144401,
          3.2472243,
          1.6424347,
          -1.8482354,
          9.190731,
          0.23712943,
          -1.8281718,
          4.874145,
          -1.5696987,
          -0.45007166,
          15.673734,
          -1.300406,
          -11.885083,
          -7.975262,
          13.089166,
          10.031324,
          -8.520221,
          -3.8277116,
          9.546913,
          5.5215306,
          -8.486495,
          12.182401,
          5.4718766,
          -7.803263,
          6.7994146,
          2.2736604,
          -0.6102269,
          -0.22050302,
          4.976756,
          -3.0931675,
          -0.5451246,
          -6.2195363,
          -8.77129,
          3.189219,
          -14.428353,
          -7.401484,
          1.6007558,
          5.3511596,
          -12.226998,
          -14.143116,
          7.0700164,
          -7.8187556,
          5.808142
         ],
         "xaxis": "x",
         "y": [
          12.152933,
          0.7596511,
          10.296794,
          1.0213454,
          11.141783,
          -9.486539,
          10.983469,
          -11.866846,
          -16.03115,
          2.2909546,
          7.3245745,
          -3.026695,
          -13.041805,
          1.6845994,
          0.6093302,
          -9.379448,
          11.679597,
          13.882968,
          -10.149707,
          4.6846075,
          -2.907061,
          5.2550488,
          2.3082154,
          -11.723655,
          -5.378123,
          8.154263,
          0.10393732,
          -5.040676,
          -0.8546924,
          10.497907,
          -10.90651,
          -0.8035073,
          -2.0673902,
          7.657025,
          -8.15762,
          15.552978,
          13.347439,
          0.398233,
          -4.5620327,
          2.8322,
          5.403129,
          1.0110519,
          -7.78426,
          -10.897762,
          -6.2053256,
          2.408055,
          1.2121688,
          7.018525,
          -1.5410968,
          6.0785856,
          8.523852,
          9.056267,
          10.437903,
          2.647043,
          -2.6857328,
          -6.566984,
          3.774217,
          8.796923,
          15.194261,
          -4.4930205,
          6.3137765,
          2.0355096,
          -0.4078594,
          -9.360646,
          15.960754,
          -4.756409,
          -2.9067245,
          -9.723048,
          -5.7455273,
          4.930662,
          12.625514,
          -11.808016,
          -4.7411494,
          -13.096084,
          2.5682018,
          -14.071455,
          8.729582,
          6.751994,
          0.1601141,
          -1.0871687,
          0.25499275,
          10.804287,
          2.6488857,
          3.0245056,
          -2.649001,
          -3.083773,
          15.082703,
          3.1022274,
          11.650792,
          3.0384686,
          -7.785139,
          -7.804713,
          0.00640972,
          -9.392355,
          1.3755524,
          -2.3413134,
          -9.439971,
          4.806527,
          -10.783534,
          8.651489,
          -13.583056,
          -7.4154778,
          3.8554757,
          15.257502,
          -7.361129,
          3.2134836,
          9.241535,
          -1.8870457,
          -14.583182,
          1.3576705,
          4.811334,
          5.5246673,
          -3.0647469,
          6.4311237,
          -8.610247,
          -13.300138,
          2.8341806,
          -5.1912494,
          -2.9180012,
          -3.3023317,
          6.0348053,
          -6.4709134,
          10.044173,
          11.522651,
          -6.1690054,
          -4.331204,
          2.280967,
          9.204004,
          -13.678855,
          0.12417382,
          11.876396,
          0.85011894,
          1.4898754,
          0.8622773,
          -3.1017103,
          -6.0701385,
          11.461465,
          -3.838107,
          9.7077465,
          1.4609528,
          -1.9873092,
          -3.8881922,
          4.571926,
          8.362274,
          0.3400524,
          11.819163,
          6.6976285,
          0.71691614,
          2.1443908,
          8.303748,
          -4.5551972,
          -0.7437671,
          -2.9910028,
          6.712193,
          10.796055,
          15.253653,
          -3.9456308,
          -7.8804097,
          6.2351513,
          -1.1942673,
          7.88214,
          -3.214612,
          13.209712,
          -1.198835,
          -6.3527875,
          -8.413251,
          -2.0747476,
          -2.2718923,
          -1.5096279,
          -10.971525,
          5.014848,
          5.8995223,
          -0.82018936,
          -2.00246,
          -6.34716,
          -5.6788774,
          5.2311435,
          -0.8606652,
          5.3759365,
          3.8590527,
          2.539977,
          -7.378442,
          10.62392,
          -13.595005,
          -8.6419735,
          5.464863,
          -1.307201,
          -5.1614428,
          -0.8782759,
          -4.0460935,
          12.955729,
          -4.6108904,
          4.7779913,
          -5.1112103,
          -6.059694,
          -8.381229,
          -1.9072429,
          2.5628657,
          -7.070952,
          13.590213,
          -1.4772367,
          3.9551928,
          -0.74527556,
          -9.84513,
          12.943439,
          -2.5160592,
          -7.170031,
          10.444515,
          -2.1718464,
          -3.778778,
          -4.614535,
          9.769881,
          4.2925754,
          -0.09314475,
          -0.99452853,
          2.556042,
          4.1875143,
          -0.7433229,
          -9.182718,
          6.691382,
          -7.9539,
          -8.208997,
          -5.3688636,
          -5.3300843,
          -1.133269,
          -3.7913878,
          6.3842087,
          6.8250027,
          -0.8892782,
          2.2336297,
          1.2914846,
          -14.475275,
          9.309077,
          -1.738896,
          14.30171,
          10.828181,
          14.62521,
          -2.7160068,
          -4.3227406,
          1.94559,
          8.058035,
          9.620206,
          0.45144585,
          1.3805916,
          -0.96918213,
          -12.808096,
          -2.0971518,
          12.114674,
          -11.029016,
          6.0805135,
          -8.187401,
          -15.661761,
          7.4026213,
          5.370062,
          4.821997,
          -13.2995825,
          -13.838412,
          1.7437031,
          1.9326565,
          -1.4394641,
          -0.67576426,
          17.641905,
          3.2840924,
          3.4189706,
          4.046379,
          15.413018,
          -3.2941802,
          9.784667,
          -7.165465,
          7.879742,
          1.6022425,
          7.660287,
          8.933599,
          6.531494,
          4.0824795,
          -11.350026,
          -12.811632,
          -5.6584115,
          3.9036252,
          -0.41513544,
          -0.27446154,
          -10.62535,
          13.374188,
          0.98500836,
          8.442199,
          1.2002327,
          14.174027,
          0.5212923,
          0.766797,
          -5.9052677,
          2.216323,
          3.0525744,
          -1.7106922,
          -12.989973,
          7.6796846,
          9.588057,
          -0.3362326,
          5.973571,
          8.975402,
          -5.160171,
          -6.57815,
          -3.9082298,
          12.393922,
          2.9798884,
          0.03528966,
          6.14028,
          11.216894,
          1.7619138,
          6.130864,
          -3.0701237,
          -7.391547,
          3.4344945,
          3.083207,
          -8.990305,
          1.7172337,
          6.356,
          -8.792454,
          -6.754097,
          -0.7274432,
          6.619196,
          13.48175,
          -4.480142,
          -5.00869,
          -6.428243,
          -0.12689854,
          -9.154032,
          -10.670436,
          -3.220304,
          6.475488,
          -9.656736,
          -7.161606,
          4.2918043,
          10.316287,
          -1.1439545,
          -16.072216,
          -5.839288,
          -6.475174,
          13.127552,
          -7.458374,
          3.9869723,
          -3.8711567,
          -0.20090447,
          -5.187433,
          0.066947825,
          -2.226165,
          9.735201,
          5.494655,
          4.6767898,
          0.5741012,
          6.522444,
          -2.6680682,
          3.3720753,
          -11.2674885,
          -3.6652,
          -11.751749,
          7.4331145,
          8.001368,
          -13.740197,
          10.823176,
          -10.284103,
          9.566688,
          -6.638185,
          -1.9452207,
          6.8364906,
          -10.260283,
          -6.142377,
          -9.561033,
          4.342532,
          2.816885,
          -4.533028,
          5.2741456,
          -3.854822,
          -1.5211835,
          12.02966,
          -6.0092196,
          -10.988969,
          9.541059,
          3.2390368,
          -7.134749,
          0.2863034,
          -2.18777,
          -4.2161245,
          7.321068,
          6.260231,
          -5.0783024,
          -6.684919,
          -10.363057,
          -0.10198021,
          -4.902489,
          10.138728,
          12.164891,
          1.43968,
          -8.235158,
          3.807534,
          12.02021,
          -5.337097,
          -9.42599,
          5.198057,
          -6.400236,
          1.6151823,
          -7.4501886,
          -10.093107,
          0.46456343,
          3.0688503,
          -0.33185768,
          -3.1963818,
          -6.181396,
          8.068962,
          1.655678,
          -10.953596,
          4.9887056,
          -13.045717,
          3.9873188,
          -4.314,
          -4.6586146,
          -1.1553029,
          0.93112904,
          13.639338,
          -0.60305417,
          -3.9178042,
          2.159607,
          5.8201976,
          -5.441761,
          -1.2344267,
          -1.5702641,
          9.194025,
          2.012704,
          4.5775766,
          -14.492065,
          9.809371,
          9.5520935,
          -7.4450307,
          12.487835,
          -6.9591436,
          -5.052006,
          6.80974,
          -5.283606,
          8.778731,
          -10.370798,
          7.8184147,
          -7.8784275,
          7.937216,
          1.6101081,
          6.5684295,
          -3.5922868,
          -3.810713,
          4.247974,
          -10.711199,
          -8.423688,
          7.9995875,
          8.186761,
          -12.060218,
          -1.9367588,
          12.101942,
          -0.59742415,
          15.179882,
          -9.792795,
          7.3713446,
          5.4296756,
          -10.734802,
          -15.6782255,
          -6.3815203,
          1.49704,
          8.012193,
          4.0134134,
          -8.360375,
          -1.1299144,
          5.814519,
          17.505613,
          9.58445,
          8.008141,
          3.7397916,
          11.969915,
          4.9431157,
          -8.0405035,
          -4.4235463,
          1.4082885,
          7.156555,
          10.77184,
          2.6410527,
          -4.3144836,
          4.4449553,
          -8.554306,
          -7.3845315,
          -12.03116,
          -1.7428504,
          -0.44723246,
          2.2919707,
          -3.7354324,
          6.6741333,
          4.6795487,
          -4.8820176,
          -1.9613998,
          3.444269,
          -2.838832,
          5.1598487,
          1.8265257,
          9.712079,
          15.219907,
          2.651989
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "cluster"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "height": 800,
        "legend": {
         "tracegroupgap": 0
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Word Embeddings (TSNE) with 8 clusters",
         "x": 0.5,
         "y": 0.95
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           6,
           2,
           6,
           6,
           3,
           0,
           3,
           7,
           0,
           2,
           3,
           1,
           0,
           0,
           6,
           3,
           6,
           6,
           6,
           3,
           6,
           3,
           3,
           7,
           2,
           3,
           1,
           2,
           6,
           0,
           7,
           6,
           4,
           2,
           5,
           7,
           6,
           2,
           5,
           2,
           0,
           6,
           6,
           0,
           0,
           6,
           5,
           6,
           2,
           6,
           3,
           0,
           6,
           0,
           6,
           6,
           5,
           6,
           6,
           0,
           3,
           6,
           2,
           5,
           0,
           0,
           2,
           0,
           0,
           6,
           7,
           7,
           2,
           3,
           6,
           4,
           6,
           1,
           2,
           6,
           6,
           3,
           5,
           1,
           3,
           2,
           2,
           6,
           6,
           6,
           6,
           0,
           2,
           4,
           2,
           0,
           6,
           7,
           7,
           6,
           7,
           6,
           6,
           6,
           2,
           7,
           7,
           1,
           2,
           2,
           6,
           3,
           7,
           3,
           6,
           2,
           1,
           7,
           0,
           7,
           6,
           0,
           6,
           0,
           0,
           6,
           0,
           3,
           0,
           2,
           6,
           0,
           2,
           6,
           2,
           6,
           1,
           3,
           3,
           6,
           3,
           3,
           6,
           0,
           5,
           2,
           3,
           6,
           2,
           6,
           3,
           2,
           5,
           2,
           5,
           6,
           3,
           4,
           6,
           2,
           6,
           6,
           3,
           0,
           6,
           6,
           6,
           7,
           0,
           0,
           6,
           0,
           3,
           1,
           2,
           3,
           6,
           6,
           6,
           6,
           6,
           0,
           6,
           6,
           5,
           6,
           4,
           0,
           6,
           5,
           0,
           0,
           0,
           1,
           0,
           3,
           5,
           3,
           5,
           6,
           4,
           2,
           6,
           6,
           2,
           6,
           2,
           6,
           7,
           7,
           5,
           6,
           6,
           0,
           6,
           4,
           0,
           2,
           0,
           2,
           4,
           6,
           2,
           0,
           2,
           5,
           2,
           6,
           0,
           7,
           4,
           2,
           0,
           6,
           6,
           6,
           5,
           4,
           6,
           3,
           6,
           0,
           6,
           2,
           6,
           0,
           0,
           0,
           6,
           6,
           6,
           7,
           6,
           0,
           6,
           2,
           3,
           6,
           0,
           7,
           0,
           0,
           3,
           5,
           5,
           7,
           6,
           3,
           0,
           3,
           7,
           6,
           6,
           3,
           6,
           1,
           0,
           6,
           0,
           6,
           6,
           6,
           5,
           3,
           6,
           3,
           6,
           6,
           0,
           6,
           0,
           6,
           7,
           2,
           2,
           3,
           7,
           6,
           3,
           0,
           1,
           0,
           5,
           2,
           7,
           3,
           0,
           3,
           5,
           3,
           5,
           0,
           3,
           4,
           2,
           1,
           0,
           6,
           6,
           6,
           5,
           6,
           0,
           0,
           0,
           0,
           0,
           2,
           3,
           0,
           6,
           0,
           2,
           5,
           4,
           2,
           2,
           5,
           0,
           6,
           6,
           0,
           2,
           6,
           4,
           1,
           6,
           5,
           2,
           6,
           6,
           6,
           2,
           3,
           6,
           6,
           0,
           3,
           0,
           0,
           0,
           2,
           2,
           1,
           0,
           0,
           3,
           0,
           7,
           6,
           2,
           2,
           7,
           4,
           0,
           5,
           0,
           0,
           0,
           2,
           2,
           2,
           5,
           6,
           7,
           2,
           6,
           6,
           4,
           0,
           6,
           6,
           6,
           7,
           7,
           4,
           6,
           3,
           3,
           6,
           0,
           1,
           2,
           5,
           6,
           3,
           6,
           3,
           6,
           6,
           6,
           6,
           6,
           6,
           2,
           5,
           6,
           0,
           6,
           2,
           6,
           3,
           0,
           2,
           2,
           1,
           0,
           0,
           6,
           4,
           5,
           4,
           0,
           5,
           6,
           5,
           6,
           3,
           5,
           6,
           4,
           0,
           3,
           4,
           1,
           2,
           4,
           6,
           6,
           0,
           5,
           6,
           3,
           0,
           6,
           4,
           0,
           6,
           6,
           1,
           2,
           2,
           4,
           2,
           2,
           6,
           6,
           6,
           4,
           0,
           6,
           0,
           6,
           0,
           5,
           2,
           6,
           4,
           2,
           0,
           5,
           6,
           4,
           5,
           4,
           7,
           7,
           6,
           4,
           6,
           6,
           0,
           0,
           7,
           3,
           3,
           2,
           2,
           0,
           5
          ],
          "colorscale": [
           [
            0,
            "#440154"
           ],
           [
            0.1111111111111111,
            "#482878"
           ],
           [
            0.2222222222222222,
            "#3e4989"
           ],
           [
            0.3333333333333333,
            "#31688e"
           ],
           [
            0.4444444444444444,
            "#26828e"
           ],
           [
            0.5555555555555556,
            "#1f9e89"
           ],
           [
            0.6666666666666666,
            "#35b779"
           ],
           [
            0.7777777777777778,
            "#6ece58"
           ],
           [
            0.8888888888888888,
            "#b5de2b"
           ],
           [
            1,
            "#fde725"
           ]
          ],
          "opacity": 0.8,
          "size": 5
         },
         "mode": "markers+text",
         "text": [
          "<PAD>",
          "<UNK>",
          "the",
          "to",
          "of",
          "and",
          "a",
          "you",
          "i",
          "is",
          "that",
          "in",
          "it",
          "for",
          "this",
          "not",
          "on",
          "be",
          "as",
          "have",
          "are",
          "your",
          "with",
          "if",
          "article",
          "was",
          "or",
          "but",
          "page",
          "my",
          "an",
          "from",
          "by",
          "do",
          "at",
          "about",
          "me",
          "so",
          "wikipedia",
          "can",
          "what",
          "there",
          "talk",
          "all",
          "has",
          "will",
          "please",
          "would",
          "its",
          "no",
          "one",
          "just",
          "like",
          "they",
          "he",
          "dont",
          "which",
          "any",
          "been",
          "should",
          "more",
          "we",
          "some",
          "other",
          "who",
          "see",
          "here",
          "also",
          "his",
          "think",
          "im",
          "because",
          "know",
          "how",
          "am",
          "people",
          "why",
          "edit",
          "articles",
          "only",
          "up",
          "out",
          "when",
          "were",
          "use",
          "then",
          "may",
          "time",
          "did",
          "them",
          "now",
          "being",
          "their",
          "than",
          "thanks",
          "even",
          "get",
          "make",
          "good",
          "had",
          "very",
          "information",
          "does",
          "could",
          "well",
          "want",
          "such",
          "sources",
          "way",
          "name",
          "these",
          "deletion",
          "pages",
          "first",
          "help",
          "new",
          "editing",
          "source",
          "go",
          "need",
          "say",
          "section",
          "edits",
          "again",
          "thank",
          "where",
          "user",
          "made",
          "many",
          "much",
          "really",
          "used",
          "most",
          "discussion",
          "ive",
          "find",
          "same",
          "deleted",
          "into",
          "fuck",
          "work",
          "those",
          "since",
          "before",
          "after",
          "point",
          "add",
          "look",
          "right",
          "read",
          "image",
          "take",
          "still",
          "over",
          "someone",
          "him",
          "two",
          "back",
          "too",
          "fact",
          "link",
          "said",
          "own",
          "youre",
          "something",
          "going",
          "blocked",
          "list",
          "stop",
          "without",
          "content",
          "hi",
          "thats",
          "editors",
          "under",
          "our",
          "block",
          "us",
          "utc",
          "added",
          "doesnt",
          "history",
          "another",
          "removed",
          "might",
          "welcome",
          "note",
          "however",
          "sure",
          "place",
          "never",
          "done",
          "her",
          "case",
          "put",
          "cant",
          "personal",
          "seems",
          "better",
          "reason",
          "using",
          "yourself",
          "actually",
          "ask",
          "comment",
          "vandalism",
          "while",
          "feel",
          "question",
          "anything",
          "believe",
          "person",
          "didnt",
          "links",
          "things",
          "both",
          "ill",
          "best",
          "comments",
          "part",
          "she",
          "hope",
          "policy",
          "against",
          "off",
          "keep",
          "already",
          "wiki",
          "free",
          "thing",
          "nothing",
          "change",
          "wrong",
          "though",
          "problem",
          "remove",
          "little",
          "subject",
          "others",
          "tag",
          "trying",
          "copyright",
          "must",
          "understand",
          "above",
          "few",
          "anyone",
          "speedy",
          "last",
          "issue",
          "give",
          "2",
          "questions",
          "years",
          "agree",
          "rather",
          "let",
          "different",
          "editor",
          "isnt",
          "long",
          "reliable",
          "world",
          "making",
          "come",
          "sorry",
          "reference",
          "mean",
          "try",
          "references",
          "continue",
          "found",
          "doing",
          "text",
          "great",
          "leave",
          "says",
          "got",
          "probably",
          "english",
          "1",
          "original",
          "every",
          "simply",
          "word",
          "users",
          "hello",
          "fair",
          "either",
          "check",
          "least",
          "adding",
          "ip",
          "show",
          "state",
          "site",
          "else",
          "delete",
          "consensus",
          "enough",
          "request",
          "opinion",
          "far",
          "created",
          "around",
          "life",
          "day",
          "between",
          "through",
          "example",
          "view",
          "reverted",
          "yes",
          "yet",
          "id",
          "etc",
          "contributions",
          "matter",
          "shit",
          "war",
          "u",
          "notable",
          "given",
          "thought",
          "material",
          "book",
          "admin",
          "write",
          "down",
          "post",
          "account",
          "having",
          "clearly",
          "encyclopedia",
          "support",
          "lot",
          "real",
          "bad",
          "message",
          "needs",
          "images",
          "tell",
          "seem",
          "called",
          "evidence",
          "maybe",
          "instead",
          "ever",
          "3",
          "correct",
          "saying",
          "clear",
          "always",
          "number",
          "important",
          "further",
          "quite",
          "perhaps",
          "old",
          "true",
          "hate",
          "until",
          "states",
          "whether",
          "consider",
          "written",
          "claim",
          "language",
          "media",
          "bit",
          "once",
          "guidelines",
          "term",
          "version",
          "criteria",
          "research",
          "nigger",
          "times",
          "theres",
          "website",
          "fucking",
          "getting",
          "review",
          "mention",
          "pov",
          "oh",
          "makes",
          "several",
          "revert",
          "considered",
          "changes",
          "words",
          "cannot",
          "idea",
          "title",
          "suck",
          "address",
          "notice",
          "based",
          "top",
          "current",
          "following",
          "each",
          "listed",
          "means",
          "group",
          "possible",
          "facts",
          "regarding",
          "care",
          "rules",
          "second",
          "main",
          "template",
          "general",
          "mentioned",
          "year",
          "attack",
          "whole",
          "course",
          "kind",
          "statement",
          "left",
          "hey",
          "date",
          "include",
          "seen",
          "three",
          "start",
          "wikipedias",
          "issues",
          "ass",
          "ok",
          "end",
          "call",
          "less",
          "topic",
          "gay",
          "suggest",
          "man",
          "including",
          "happy",
          "sense",
          "big",
          "create",
          "provide",
          "days",
          "myself",
          "american",
          "redirect",
          "known",
          "appropriate",
          "sentence",
          "move",
          "love",
          "changed",
          "notability",
          "explain",
          "started",
          "included",
          "project",
          "removing",
          "mind",
          "anyway",
          "info",
          "school",
          "2005",
          "next",
          "looking",
          "although",
          "wont",
          "picture",
          "four",
          "relevant",
          "die",
          "style",
          "answer",
          "sign",
          "away",
          "per",
          "youve",
          "warning",
          "order",
          "interest",
          "recent",
          "community",
          "summary",
          "later",
          "lol",
          "claims",
          "discuss",
          "currently",
          "interested",
          "attacks",
          "policies",
          "especially",
          "wish",
          "wrote",
          "able",
          "specific"
         ],
         "textposition": "top center",
         "type": "scatter3d",
         "x": [
          0.52892125,
          -25.12713,
          -13.646563,
          24.737314,
          0.42174953,
          -14.759976,
          12.627207,
          18.502642,
          15.514796,
          -26.18635,
          4.978895,
          13.54237,
          -40.076748,
          15.977654,
          -22.102169,
          25.197897,
          -5.2169595,
          -17.736177,
          14.323281,
          -12.380609,
          6.9041386,
          12.827124,
          20.984583,
          -34.00962,
          -20.639742,
          3.607656,
          -13.9226,
          34.46178,
          -37.477684,
          -30.281923,
          31.771824,
          30.540611,
          2.9770525,
          6.333767,
          -1.9649647,
          -46.442616,
          -29.033482,
          20.37789,
          12.554749,
          -39.09051,
          9.565064,
          -0.120818615,
          41.983673,
          -22.03217,
          -8.9963455,
          -13.922888,
          -6.079862,
          17.24479,
          -31.77588,
          -18.152771,
          -31.2028,
          33.93402,
          -39.329494,
          -9.043857,
          -40.31668,
          -7.835828,
          -15.073233,
          1.8030629,
          -27.299868,
          -11.956614,
          -0.09097798,
          -7.4676766,
          10.736093,
          -20.988083,
          -53.71286,
          -25.535088,
          -23.984182,
          -27.036884,
          -4.6586742,
          -3.2870023,
          -14.80742,
          -32.900337,
          15.952603,
          -3.509716,
          -5.4893365,
          -24.027042,
          -30.294744,
          -14.544725,
          22.903717,
          4.4873853,
          26.502876,
          -9.168703,
          22.88735,
          8.277437,
          34.804573,
          9.830636,
          -40.78037,
          -38.10465,
          -23.427694,
          -41.944874,
          5.4277787,
          7.9995904,
          30.200901,
          -2.1703966,
          16.625692,
          17.828753,
          15.928641,
          18.589266,
          28.510592,
          -21.627678,
          -26.683968,
          28.511507,
          44.548008,
          -34.447186,
          34.471836,
          -24.292799,
          -17.40697,
          -31.014845,
          -6.130922,
          6.647728,
          12.453847,
          26.82853,
          -10.760783,
          5.236456,
          3.3325038,
          -3.2540917,
          -33.3894,
          26.23513,
          -28.236433,
          18.301271,
          16.063896,
          12.476998,
          -16.34787,
          -31.897007,
          9.987989,
          2.639187,
          -9.721686,
          -0.6850386,
          -23.550253,
          -23.417305,
          -27.15729,
          -4.4607553,
          -14.824096,
          25.712778,
          -13.141678,
          -2.2281907,
          -28.04249,
          -27.43412,
          -16.411612,
          4.2274857,
          -17.02267,
          45.39872,
          16.500395,
          -35.706818,
          -15.152187,
          6.419362,
          -1.4964671,
          -17.7863,
          -11.87979,
          3.9040482,
          17.47845,
          9.903776,
          22.977547,
          2.272723,
          -35.40329,
          -29.752394,
          12.653839,
          23.302164,
          35.127445,
          17.367342,
          -27.574505,
          -17.346827,
          -12.955792,
          -28.917643,
          -50.6564,
          49.761986,
          -3.8908565,
          -9.0901575,
          18.50563,
          0.709886,
          15.411366,
          -17.196758,
          20.851732,
          3.5673275,
          12.476633,
          41.40899,
          41.538433,
          24.097876,
          25.915247,
          29.897762,
          -31.391014,
          -40.712555,
          18.087076,
          -9.623719,
          33.332558,
          -22.551424,
          -38.071278,
          0.13944238,
          -25.145483,
          -30.572369,
          -14.654444,
          14.303028,
          0.814509,
          34.1736,
          34.178856,
          -1.9457612,
          5.360012,
          -14.420695,
          7.9335694,
          11.124508,
          13.645482,
          -13.524529,
          29.25925,
          -12.109584,
          -22.600117,
          11.095033,
          27.346375,
          -48.93149,
          14.988097,
          9.103288,
          32.52783,
          40.037914,
          40.91432,
          -8.30425,
          32.769108,
          -12.103579,
          24.15145,
          26.153114,
          -3.1962743,
          0.09455994,
          18.255573,
          27.835281,
          26.840233,
          -0.63151646,
          22.33674,
          18.009398,
          4.2899804,
          -4.0895305,
          12.8664465,
          -1.8893803,
          11.930945,
          -15.334286,
          27.861546,
          -1.9002188,
          -19.50483,
          -4.1408706,
          -0.13756807,
          11.432101,
          -5.4746876,
          -16.25048,
          -13.08703,
          -20.50836,
          19.005306,
          22.996778,
          -26.258957,
          30.155888,
          6.1923027,
          -34.886696,
          7.7372293,
          -18.014381,
          14.947175,
          -14.561473,
          -5.235745,
          -11.715312,
          -13.804792,
          22.609724,
          -8.327611,
          17.581554,
          -11.006681,
          14.218653,
          -31.124813,
          -45.450943,
          -5.7406597,
          -20.093819,
          -10.394948,
          -30.485878,
          6.130102,
          1.3968918,
          -31.405077,
          14.013428,
          -9.09537,
          5.3466525,
          -6.3942237,
          -23.035679,
          15.362598,
          -33.479324,
          -3.3531814,
          1.380899,
          18.9904,
          23.109402,
          32.61415,
          -20.273983,
          -36.48132,
          7.9874086,
          -19.27818,
          9.904062,
          -0.69131315,
          -22.677555,
          21.938452,
          -33.90592,
          -1.9755994,
          -17.733763,
          11.884108,
          -5.609,
          -20.777264,
          -15.794001,
          -20.123417,
          -44.647285,
          -20.538809,
          29.062733,
          45.054913,
          29.942736,
          17.850677,
          19.19994,
          -15.187394,
          6.4387403,
          -24.043766,
          -1.797987,
          -23.410368,
          21.276539,
          -1.7823588,
          3.3140302,
          0.15350647,
          -4.8066287,
          19.175669,
          -14.311842,
          3.760082,
          46.83885,
          12.747554,
          31.278086,
          24.764278,
          4.554752,
          -4.696476,
          9.366774,
          -20.98478,
          -7.3754983,
          -12.04307,
          -45.308372,
          22.884628,
          -7.4342937,
          21.981937,
          30.661625,
          4.5698256,
          8.513372,
          -30.475624,
          -3.8580542,
          43.186035,
          -32.49585,
          -9.587914,
          41.898685,
          -6.226858,
          12.681404,
          -14.671815,
          -8.062275,
          15.794502,
          0.14552543,
          32.725845,
          -9.059259,
          5.368617,
          -0.78230345,
          11.508444,
          -24.174198,
          -32.400135,
          27.39029,
          3.908403,
          8.418988,
          1.2147554,
          48.004536,
          6.75856,
          16.826754,
          2.303336,
          -7.7208424,
          23.75442,
          -15.958478,
          -30.07358,
          8.742568,
          23.542614,
          34.690685,
          9.772597,
          -2.8417032,
          13.48598,
          8.278193,
          11.796011,
          -7.2595677,
          11.170592,
          -22.087952,
          -26.541832,
          25.619995,
          -9.181994,
          -17.445742,
          -36.534702,
          9.859767,
          20.12532,
          -2.021025,
          4.401741,
          -46.46325,
          54.371723,
          -4.782794,
          7.980615,
          39.11465,
          -35.90682,
          -7.460236,
          -15.515678,
          16.481401,
          -29.268919,
          -19.601398,
          29.993322,
          33.778942,
          15.282719,
          17.615498,
          -10.580729,
          -13.414678,
          41.66747,
          42.777454,
          -1.258242,
          -30.530819,
          -11.817317,
          -7.2800856,
          3.786199,
          -22.917826,
          -5.2470703,
          -37.52771,
          39.861435,
          -9.287812,
          44.9276,
          -44.63627,
          -21.24586,
          39.39403,
          9.783932,
          -24.219776,
          3.3565247,
          16.417253,
          21.703102,
          8.100893,
          -3.232685,
          32.05219,
          -13.452315,
          21.808184,
          20.74389,
          -22.346378,
          -1.084989,
          29.745548,
          10.919169,
          5.9818716,
          10.865283,
          33.79393,
          -4.262345,
          7.0829487,
          6.9750986,
          4.3844028,
          28.144133,
          29.693314,
          13.333501,
          -39.37667,
          -32.766205,
          -17.757162,
          -12.1793585,
          -25.083576,
          -6.1075897,
          11.183846,
          -19.965475,
          47.23212,
          -10.981707,
          -31.576096,
          -20.359415,
          3.4844291,
          -17.1956,
          21.864033,
          15.130434,
          32.769474,
          -34.843338,
          26.103216,
          -12.504509,
          7.7568655,
          -10.014169,
          3.3697343,
          -8.848668,
          -3.0151865,
          -43.85964,
          39.77905,
          1.7001951,
          -27.802269,
          7.5398693,
          -15.471698,
          2.9230385,
          28.571566,
          -40.74864,
          -2.168858,
          0.6174405,
          -14.096511,
          27.765388,
          -5.257067,
          30.260918,
          -5.244007,
          44.460182,
          -12.721061,
          9.724993,
          -2.6800697,
          28.037657,
          -7.878933,
          17.277088,
          28.139753,
          1.5175546,
          32.59949,
          -21.975235,
          -2.2807,
          -17.338722,
          24.359533,
          6.6565433,
          -7.6881733
         ],
         "y": [
          -31.067902,
          -14.464576,
          19.29899,
          -22.407976,
          -13.722752,
          -16.049557,
          40.95426,
          36.048107,
          22.45204,
          -23.64697,
          -4.5996413,
          15.813148,
          22.620752,
          -13.143889,
          16.012238,
          4.103831,
          -13.657098,
          -34.748783,
          9.0648155,
          35.9444,
          4.7002625,
          -0.11344549,
          -18.431929,
          20.247068,
          43.18468,
          32.277546,
          8.950553,
          5.433542,
          -12.999877,
          4.093234,
          6.4088435,
          -5.7108073,
          5.868594,
          41.297333,
          -16.092215,
          11.144902,
          -28.959286,
          0.2680006,
          2.6977358,
          9.22763,
          23.496618,
          40.57628,
          23.643862,
          15.809141,
          -9.180075,
          -9.320802,
          12.624535,
          25.131723,
          6.2678175,
          -21.158056,
          -4.3097277,
          -35.611446,
          6.2190347,
          27.570993,
          0.21079913,
          -11.828451,
          -34.081932,
          -29.233007,
          -31.322178,
          -9.390805,
          25.457203,
          20.971014,
          12.236731,
          33.52805,
          -13.969266,
          2.4764216,
          4.280767,
          11.719587,
          -7.3979826,
          -3.2193816,
          4.5355134,
          16.342772,
          -3.5317016,
          -11.710891,
          -33.47733,
          20.63558,
          -13.12622,
          -16.472837,
          -3.2495189,
          11.466495,
          -16.037283,
          15.833769,
          -23.554352,
          28.812752,
          17.658016,
          40.928574,
          -17.029503,
          6.466196,
          -34.977303,
          12.496096,
          0.41364062,
          -0.44744754,
          -5.63783,
          -3.2473183,
          -35.358067,
          -0.3014449,
          15.370521,
          -29.742676,
          -33.782925,
          -2.3716102,
          19.18226,
          -20.936678,
          4.365528,
          -16.945803,
          19.621387,
          1.8768373,
          26.950953,
          -0.3805267,
          -25.418736,
          25.788904,
          -11.669163,
          -40.98109,
          -1.575969,
          -37.98344,
          -6.173182,
          -15.804726,
          15.950885,
          16.57274,
          7.0402546,
          19.876532,
          15.417391,
          -47.25475,
          -10.883975,
          -18.962685,
          -33.810413,
          7.9483337,
          -39.241302,
          37.668434,
          21.087742,
          -10.379972,
          -32.597378,
          17.755106,
          -20.702484,
          28.469238,
          3.2883387,
          -1.4767351,
          -39.003395,
          34.311035,
          26.365719,
          11.356762,
          8.625506,
          6.92223,
          -10.296574,
          36.354176,
          -5.3600693,
          -15.49034,
          20.0573,
          15.023244,
          17.110584,
          -32.472748,
          0.14364935,
          13.132621,
          0.20123656,
          7.9749346,
          -24.512478,
          -24.715647,
          -11.39189,
          24.778603,
          22.21371,
          4.9272456,
          -10.609513,
          11.473143,
          15.5083475,
          11.713398,
          -3.3824527,
          -8.986159,
          23.979786,
          30.921478,
          -18.761868,
          -42.78665,
          -24.073853,
          -20.334717,
          -15.802535,
          -20.717976,
          -40.804684,
          18.151493,
          -4.2076483,
          -5.825398,
          33.09436,
          0.1389194,
          -19.759378,
          -5.4878774,
          44.243828,
          -24.862371,
          -16.358194,
          -27.942215,
          2.3296282,
          -21.755346,
          8.015884,
          31.884525,
          -33.414658,
          -18.573427,
          48.7477,
          15.819889,
          9.934739,
          14.1839485,
          16.088694,
          4.6158633,
          29.292421,
          6.3342004,
          -0.55925673,
          -0.9444161,
          -2.0810559,
          -9.107896,
          16.962957,
          -28.594782,
          16.57277,
          9.501219,
          10.95952,
          -7.440402,
          8.013916,
          -15.858073,
          -0.6323824,
          26.135242,
          -10.11853,
          8.7592745,
          -29.581417,
          -8.546128,
          -20.967922,
          31.193666,
          20.040886,
          -3.171071,
          9.977671,
          -14.388082,
          1.474429,
          -10.054236,
          -5.3219795,
          -25.34134,
          -8.944978,
          15.129367,
          -10.016213,
          -18.092875,
          35.080536,
          0.7208089,
          -36.961994,
          -14.676488,
          -18.763346,
          -34.707584,
          28.060951,
          5.8990912,
          -43.773834,
          29.207174,
          9.186416,
          -11.749306,
          9.995257,
          -24.260489,
          8.969608,
          -17.795034,
          9.371724,
          -15.260669,
          -7.770028,
          -47.280064,
          -36.065277,
          -15.694673,
          -8.87035,
          -44.085503,
          -20.8384,
          -21.931032,
          22.525463,
          27.97158,
          19.623783,
          -6.601531,
          8.532996,
          0.2078607,
          -31.46362,
          -30.317507,
          -1.5755328,
          -52.40249,
          8.1406145,
          32.751278,
          36.48425,
          20.83785,
          -52.921677,
          -13.557852,
          -6.9213595,
          26.066383,
          -10.669713,
          8.728986,
          32.013477,
          -7.6114454,
          31.381475,
          46.82477,
          -30.088013,
          -5.901977,
          -0.5251036,
          15.076309,
          -15.810272,
          11.899818,
          -25.959879,
          10.971664,
          -36.38411,
          -22.319298,
          -0.9953979,
          -42.52698,
          20.184319,
          32.907757,
          6.016139,
          17.721094,
          -12.581869,
          28.33292,
          -16.110619,
          7.9835286,
          45.887493,
          -22.81931,
          30.236422,
          -1.4063022,
          -19.407003,
          10.459627,
          -21.610722,
          12.589069,
          -3.0067005,
          31.184654,
          19.680754,
          2.7200477,
          -11.585913,
          -8.389275,
          -9.611579,
          -21.838654,
          7.355027,
          -24.230286,
          21.25827,
          -7.0621657,
          -23.838747,
          -16.62518,
          -0.21348193,
          -2.6437843,
          0.36554193,
          4.392353,
          25.936556,
          -20.41026,
          16.139683,
          -10.058073,
          48.564762,
          4.3846936,
          34.021435,
          -3.77305,
          -10.600336,
          -7.6063156,
          -0.03592155,
          4.2852964,
          6.150874,
          -7.631804,
          -29.54571,
          12.915572,
          1.0061269,
          36.198765,
          15.662784,
          -27.754343,
          -2.3487945,
          19.48511,
          -30.958881,
          -4.954342,
          20.55845,
          10.607416,
          -14.819591,
          39.119022,
          -25.304668,
          10.451358,
          -19.699879,
          3.2193246,
          -34.621056,
          42.7363,
          -14.074395,
          -18.77458,
          -43.637035,
          -22.999695,
          8.766212,
          -6.1664524,
          33.619164,
          5.754671,
          6.782551,
          4.22217,
          25.825508,
          -16.943544,
          -28.089079,
          32.039463,
          -12.070357,
          -8.079127,
          15.865643,
          24.479836,
          -4.251791,
          -1.5565127,
          36.094353,
          3.1082876,
          -14.708284,
          -4.158344,
          1.3910306,
          24.492865,
          -17.0982,
          -13.843949,
          -6.5581093,
          26.898596,
          24.928864,
          -11.379226,
          -29.586353,
          -25.640572,
          7.989571,
          -7.451226,
          -44.787613,
          -27.912352,
          10.121573,
          47.73986,
          -19.105879,
          10.596856,
          9.353759,
          -2.522385,
          -21.114794,
          6.958992,
          -3.8844454,
          28.456789,
          -2.4353034,
          24.36701,
          0.86881757,
          -4.517819,
          -7.2134085,
          -2.3107712,
          17.763998,
          -27.288933,
          -15.082894,
          -1.7568678,
          -38.83184,
          21.30529,
          8.235475,
          19.03366,
          36.016174,
          31.238901,
          38.34758,
          -29.487167,
          15.659217,
          -6.6386595,
          -35.694458,
          -27.009735,
          43.78718,
          27.282656,
          -19.43694,
          -28.799568,
          -17.944859,
          -22.058474,
          -46.327957,
          16.57998,
          -3.105535,
          -36.768135,
          8.241784,
          -22.431139,
          -10.204463,
          -0.15748191,
          42.4072,
          42.298996,
          9.503294,
          34.08722,
          -46.3141,
          4.6059575,
          13.668687,
          -2.6686366,
          4.7942533,
          24.56557,
          29.563902,
          -40.01059,
          23.448654,
          3.784637,
          27.838207,
          10.034044,
          18.184717,
          26.673033,
          24.090853,
          -33.331528,
          0.7295827,
          -45.54798,
          -19.845892,
          -20.597921,
          -26.009413,
          -3.8400016,
          -27.881094,
          -3.3841972,
          -12.502385,
          1.4069786,
          16.909822,
          -29.518522,
          50.945583,
          -33.921234,
          6.6207623,
          18.383175,
          -12.194631,
          2.3976533,
          23.74393,
          7.2725954,
          19.600985,
          25.74248,
          7.725048,
          -29.546272,
          28.041327,
          23.657585,
          -25.765993,
          -22.70304,
          30.149525,
          32.47093,
          -15.373617,
          45.233627,
          21.470078,
          -35.34363
         ],
         "z": [
          -38.896214,
          28.878252,
          -18.281776,
          -2.811755,
          -24.836172,
          -43.638184,
          6.66408,
          28.48054,
          22.163935,
          -30.525505,
          -22.27601,
          -32.41462,
          -3.0560815,
          39.402164,
          27.852541,
          -35.716095,
          -21.299627,
          -15.034694,
          5.5810657,
          1.0879189,
          -10.199728,
          -28.854212,
          24.151176,
          7.87133,
          -13.029893,
          -11.595836,
          -6.5966616,
          25.067276,
          22.184917,
          -1.0980773,
          -19.111364,
          19.898579,
          0.8461815,
          -23.28575,
          -0.42743316,
          3.780902,
          3.0144088,
          -23.720747,
          -3.7548008,
          -29.77238,
          1.8959603,
          29.259083,
          1.8675598,
          42.59135,
          -5.360714,
          -31.77233,
          0.951746,
          -36.771774,
          -19.129425,
          -13.709651,
          11.872665,
          -7.4171166,
          1.5207199,
          -8.401529,
          22.74505,
          -0.48336917,
          13.64821,
          1.4143018,
          -5.064557,
          14.821648,
          -22.261969,
          4.630815,
          44.990166,
          -6.9722195,
          -6.469868,
          39.443474,
          -31.828318,
          -6.276916,
          -10.517314,
          -22.152231,
          48.4211,
          3.161259,
          -48.35419,
          32.26336,
          -5.9774165,
          -9.079528,
          16.500221,
          24.699398,
          -18.621172,
          -12.883817,
          12.645917,
          -24.295969,
          19.72756,
          12.350734,
          -11.476556,
          19.792425,
          -10.618788,
          35.45887,
          20.303844,
          -24.520103,
          10.48828,
          4.381615,
          -17.730518,
          41.24653,
          -13.468056,
          31.84642,
          3.3929102,
          -24.348223,
          24.609737,
          2.2330906,
          -17.089014,
          -20.020164,
          -1.2134614,
          -13.645419,
          0.5505488,
          -13.013632,
          -28.664412,
          26.961962,
          44.329445,
          40.873962,
          -20.476076,
          -18.274597,
          3.9061062,
          -16.41985,
          -3.0233092,
          38.25298,
          31.744938,
          -4.736292,
          -36.119698,
          -28.295973,
          -10.462307,
          -12.922994,
          -5.8764596,
          -1.5317258,
          24.90808,
          20.526875,
          29.263687,
          -7.1727934,
          -24.623339,
          20.252096,
          11.594521,
          -13.0562935,
          -25.664661,
          -2.5765827,
          7.33534,
          13.516838,
          9.1523,
          6.5547214,
          -16.37264,
          10.814507,
          4.6494784,
          -24.430487,
          -26.45962,
          -9.379822,
          39.649025,
          -30.529444,
          -33.16775,
          -5.066965,
          9.5355015,
          -26.11514,
          -3.3079824,
          17.866898,
          26.04081,
          -22.839392,
          29.577618,
          -16.04073,
          -12.624765,
          36.35708,
          -29.392258,
          -14.232292,
          36.495514,
          -16.478395,
          -41.026543,
          -18.247314,
          1.8259906,
          5.9957104,
          29.592989,
          38.812355,
          5.9009814,
          4.048043,
          -28.556679,
          11.248428,
          0.49477082,
          24.300947,
          23.268507,
          14.8289,
          14.313733,
          15.957951,
          -24.497986,
          10.5808935,
          -35.00896,
          10.656624,
          4.240455,
          33.872997,
          -8.1290655,
          31.424826,
          -14.522808,
          9.908685,
          3.4121785,
          1.3378872,
          -7.2068753,
          -13.651135,
          12.543403,
          17.34508,
          0.92464894,
          39.58937,
          27.89262,
          -25.345736,
          32.10727,
          -38.66878,
          19.131218,
          -13.069677,
          -9.495205,
          -44.200844,
          -41.56876,
          -6.9212847,
          -22.299906,
          -9.104029,
          24.699139,
          -11.022984,
          18.69429,
          17.216951,
          -10.112579,
          21.448057,
          5.777664,
          -30.17365,
          13.785663,
          9.325295,
          -5.1808715,
          -26.46947,
          35.057438,
          -34.23817,
          -1.8552146,
          15.4165535,
          -13.221046,
          -8.67993,
          -36.239216,
          -28.423542,
          2.0348887,
          13.24425,
          33.054585,
          42.71207,
          9.035275,
          -2.793713,
          -21.917086,
          -29.593529,
          -45.34069,
          5.355312,
          -18.202677,
          -35.581146,
          -3.218079,
          -34.366287,
          48.02788,
          -26.328503,
          9.40836,
          -33.627922,
          31.249517,
          9.399531,
          3.9445033,
          -14.630775,
          11.91679,
          11.779867,
          -25.105274,
          9.678812,
          -16.492462,
          10.743051,
          39.373184,
          29.223207,
          -4.8958163,
          -24.589102,
          20.296143,
          -24.814554,
          -33.082165,
          -16.71946,
          15.797263,
          -10.878676,
          -12.15022,
          -5.7330966,
          14.480865,
          -7.573824,
          8.940982,
          -9.629412,
          -2.493545,
          -19.432627,
          -32.625824,
          11.482699,
          25.525375,
          -33.554527,
          13.531017,
          1.7658291,
          -8.020276,
          9.649763,
          2.8589637,
          27.305197,
          -3.8322418,
          -20.296995,
          -39.0736,
          23.100399,
          -7.62639,
          21.717188,
          -2.162964,
          -2.2334929,
          43.132954,
          -13.494317,
          3.132044,
          -24.755987,
          23.943422,
          16.005405,
          3.5600448,
          25.091763,
          -3.0992057,
          -8.75317,
          -16.094854,
          -43.018414,
          21.66836,
          -29.716932,
          -3.1629395,
          -45.435577,
          9.215622,
          28.205732,
          54.202507,
          7.715092,
          5.6257954,
          40.488415,
          22.563694,
          27.80914,
          12.303792,
          -1.3255802,
          16.584051,
          1.6143026,
          7.298172,
          -49.964764,
          8.754504,
          10.441231,
          22.309923,
          -40.366966,
          -51.475227,
          19.128544,
          -13.495901,
          -10.584155,
          -19.388086,
          33.773727,
          -0.9289482,
          45.720863,
          -22.03012,
          7.543628,
          -1.4391289,
          -10.703851,
          28.563942,
          -5.9542174,
          7.8362184,
          21.83793,
          -34.15808,
          -7.354626,
          37.448273,
          0.1630626,
          29.944479,
          22.126741,
          31.58985,
          -24.554422,
          -0.34933126,
          -36.27273,
          -29.175072,
          29.762495,
          45.040363,
          -30.366724,
          -11.378037,
          4.3379145,
          32.095013,
          8.410287,
          12.068092,
          -18.20139,
          -16.334751,
          18.138735,
          -12.340947,
          11.564129,
          -40.655,
          31.999388,
          16.477629,
          17.757065,
          -31.172104,
          -51.284023,
          -18.52328,
          -16.793951,
          12.671199,
          25.674778,
          5.689011,
          41.179607,
          28.822721,
          16.329798,
          25.272808,
          -48.995274,
          -9.165767,
          -18.523636,
          -10.102363,
          6.458557,
          -3.8224711,
          17.542835,
          -5.200239,
          22.866962,
          -1.0451274,
          9.001039,
          33.98082,
          -38.012604,
          16.681631,
          -35.8158,
          -32.09194,
          -29.224442,
          19.599102,
          34.031796,
          33.152233,
          14.728967,
          -22.339018,
          -10.233565,
          -7.1384306,
          -23.949924,
          0.6901477,
          -16.330276,
          22.553516,
          30.582335,
          -27.6941,
          -7.4828577,
          3.9450536,
          17.097517,
          -18.680748,
          -11.4607525,
          16.609444,
          -11.374349,
          20.935987,
          12.0799885,
          -5.294074,
          -5.401323,
          -2.1407192,
          22.55225,
          17.10307,
          9.120874,
          24.547579,
          7.831633,
          15.20782,
          -6.3720527,
          16.242353,
          -18.846132,
          -16.947823,
          25.380226,
          -0.27105105,
          3.6738265,
          18.73035,
          -20.489323,
          5.7174625,
          -4.271435,
          -42.410053,
          0.3046383,
          -19.063387,
          -23.195755,
          -26.884249,
          11.986884,
          -1.7431297,
          6.7716503,
          39.596928,
          -2.8718617,
          -2.0632327,
          22.14927,
          17.59619,
          -4.4004917,
          30.595684,
          -41.317806,
          -2.254084,
          -2.260841,
          0.7542679,
          -24.804996,
          -23.871113,
          5.742368,
          -1.0461371,
          -11.7973585,
          -32.213654,
          36.05857,
          -6.9090643,
          16.902485,
          0.52693504,
          13.281062,
          -18.845602,
          -44.08102,
          -38.239468,
          -22.707312,
          2.2822344,
          -0.25715536,
          -14.379198,
          -22.36475,
          -6.7740083,
          3.5599065,
          14.137421,
          50.12694,
          -6.228089,
          26.741142,
          -15.664668,
          19.192429,
          13.606498,
          -1.230478,
          36.085365,
          -18.477585,
          6.1738205,
          19.771906,
          24.366652,
          31.11334,
          11.307254,
          -39.2778,
          -26.809618,
          -1.0451807,
          -45.917873,
          3.567571
         ]
        }
       ],
       "layout": {
        "height": 800,
        "scene": {
         "xaxis": {
          "title": {
           "text": "Dimension 1"
          }
         },
         "yaxis": {
          "title": {
           "text": "Dimension 2"
          }
         },
         "zaxis": {
          "title": {
           "text": "Dimension 3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Word Embeddings Visualization",
         "y": 0.95
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "class WordEmbeddingVisualizer:\n",
    "    \"\"\"\n",
    "    Creates interactive visualizations of word embeddings in latent space\n",
    "    with clustering and dynamic exploration capabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, preprocessor):\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.embeddings = None\n",
    "        self.words = None\n",
    "        \n",
    "    def extract_embeddings(self, n_words=1000):\n",
    "        \"\"\"Extract embeddings from the model for visualization\"\"\"\n",
    "        # Get most common words\n",
    "        words = list(self.preprocessor.word2idx.keys())[:n_words]\n",
    "        word_indices = [self.preprocessor.word2idx[word] for word in words]\n",
    "        \n",
    "        # Convert to tensor and get embeddings\n",
    "        indices_tensor = torch.tensor(word_indices).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.model.embedding(indices_tensor).cpu().numpy()\n",
    "            \n",
    "        self.embeddings = embeddings\n",
    "        self.words = words\n",
    "        return embeddings, words\n",
    "    \n",
    "    def reduce_dimensions(self, method='tsne', n_components=2):\n",
    "        \"\"\"Reduce embedding dimensions for visualization\"\"\"\n",
    "        if self.embeddings is None:\n",
    "            self.extract_embeddings()\n",
    "            \n",
    "        if method.lower() == 'tsne':\n",
    "            reducer = TSNE(n_components=n_components, \n",
    "                         random_state=42,\n",
    "                         perplexity=min(30, len(self.embeddings)-1))\n",
    "            reduced_embeddings = reducer.fit_transform(self.embeddings)\n",
    "        else:\n",
    "            try:\n",
    "                from umap.umap_ import UMAP\n",
    "                reducer = UMAP(n_components=n_components, random_state=42)\n",
    "                reduced_embeddings = reducer.fit_transform(self.embeddings)\n",
    "            except ImportError:\n",
    "                print(\"UMAP not available. Falling back to t-SNE...\")\n",
    "                reducer = TSNE(n_components=n_components, \n",
    "                             random_state=42,\n",
    "                             perplexity=min(30, len(self.embeddings)-1))\n",
    "                reduced_embeddings = reducer.fit_transform(self.embeddings)\n",
    "                \n",
    "        return reduced_embeddings\n",
    "    \n",
    "    def cluster_words(self, n_clusters=5):\n",
    "        \"\"\"Cluster words based on their embeddings\"\"\"\n",
    "        if self.embeddings is None:\n",
    "            self.extract_embeddings()\n",
    "            \n",
    "        kmeans = KMeans(n_clusters=min(n_clusters, len(self.embeddings)), \n",
    "                       random_state=42)\n",
    "        clusters = kmeans.fit_predict(self.embeddings)\n",
    "        return clusters\n",
    "    \n",
    "    def create_interactive_plot(self, reduction_method='tsne', n_clusters=5):\n",
    "        \"\"\"Create an interactive plot of word embeddings\"\"\"\n",
    "        # Reduce dimensions\n",
    "        reduced_embeddings = self.reduce_dimensions(method=reduction_method)\n",
    "        \n",
    "        # Get clusters\n",
    "        clusters = self.cluster_words(n_clusters=n_clusters)\n",
    "        \n",
    "        # Create DataFrame for plotting\n",
    "        df = pd.DataFrame({\n",
    "            'x': reduced_embeddings[:, 0],\n",
    "            'y': reduced_embeddings[:, 1],\n",
    "            'word': self.words,\n",
    "            'cluster': clusters\n",
    "        })\n",
    "        \n",
    "        # Create interactive plot\n",
    "        fig = px.scatter(\n",
    "            df,\n",
    "            x='x',\n",
    "            y='y',\n",
    "            color='cluster',\n",
    "            hover_data=['word'],\n",
    "            text='word',\n",
    "            title=f'Word Embeddings ({reduction_method.upper()}) with {n_clusters} clusters'\n",
    "        )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_traces(\n",
    "            textposition='top center',\n",
    "            marker=dict(size=8),\n",
    "            textfont=dict(size=10)\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            height=800,\n",
    "            showlegend=True,\n",
    "            title_x=0.5,\n",
    "            title_y=0.95\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def create_3d_plot(self, n_clusters=5):\n",
    "        \"\"\"Create 3D interactive plot of word embeddings\"\"\"\n",
    "        # Get 3D embeddings using t-SNE\n",
    "        reduced_embeddings = self.reduce_dimensions(method='tsne', n_components=3)\n",
    "        clusters = self.cluster_words(n_clusters=n_clusters)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'x': reduced_embeddings[:, 0],\n",
    "            'y': reduced_embeddings[:, 1],\n",
    "            'z': reduced_embeddings[:, 2],\n",
    "            'word': self.words,\n",
    "            'cluster': clusters\n",
    "        })\n",
    "        \n",
    "        # Create 3D scatter plot\n",
    "        fig = go.Figure(data=[go.Scatter3d(\n",
    "            x=df['x'],\n",
    "            y=df['y'],\n",
    "            z=df['z'],\n",
    "            mode='markers+text',\n",
    "            text=df['word'],\n",
    "            hoverinfo='text',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=df['cluster'],\n",
    "                colorscale='Viridis',\n",
    "                opacity=0.8\n",
    "            ),\n",
    "            textposition='top center'\n",
    "        )])\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=dict(\n",
    "                text='3D Word Embeddings Visualization',\n",
    "                y=0.95\n",
    "            ),\n",
    "            scene=dict(\n",
    "                xaxis_title='Dimension 1',\n",
    "                yaxis_title='Dimension 2',\n",
    "                zaxis_title='Dimension 3'\n",
    "            ),\n",
    "            height=800\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def find_similar_words(self, word, n=5):\n",
    "        \"\"\"Find most similar words based on embedding distance\"\"\"\n",
    "        if word not in self.words:\n",
    "            return []\n",
    "            \n",
    "        word_idx = self.words.index(word)\n",
    "        word_embedding = self.embeddings[word_idx]\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = np.linalg.norm(self.embeddings - word_embedding, axis=1)\n",
    "        closest_indices = np.argsort(distances)[1:n+1]  # Exclude the word itself\n",
    "        \n",
    "        similar_words = [(self.words[idx], distances[idx]) for idx in closest_indices]\n",
    "        return similar_words\n",
    "\n",
    "def visualize_embeddings(model, preprocessor, n_words=500, n_clusters=8):\n",
    "    \"\"\"\n",
    "    Creates both 2D and 3D visualizations of word embeddings\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained model with embedding layer\n",
    "    - preprocessor: text preprocessor with vocabulary\n",
    "    - n_words: number of words to visualize\n",
    "    - n_clusters: number of clusters for visualization\n",
    "    \n",
    "    Returns:\n",
    "    - fig_2d: 2D interactive plot\n",
    "    - fig_3d: 3D interactive plot\n",
    "    - visualizer: WordEmbeddingVisualizer instance\n",
    "    \"\"\"\n",
    "    visualizer = WordEmbeddingVisualizer(model, preprocessor)\n",
    "    \n",
    "    # Extract embeddings\n",
    "    print(\"Extracting embeddings...\")\n",
    "    visualizer.extract_embeddings(n_words=n_words)\n",
    "    \n",
    "    # Create 2D visualization\n",
    "    print(\"Creating 2D visualization...\")\n",
    "    fig_2d = visualizer.create_interactive_plot(reduction_method='tsne', \n",
    "                                              n_clusters=n_clusters)\n",
    "    \n",
    "    # Create 3D visualization\n",
    "    print(\"Creating 3D visualization...\")\n",
    "    fig_3d = visualizer.create_3d_plot(n_clusters=n_clusters)\n",
    "    \n",
    "    # Find similar words example\n",
    "    sample_word = visualizer.words[0]\n",
    "    similar_words = visualizer.find_similar_words(sample_word, n=5)\n",
    "    print(f\"\\nWords most similar to '{sample_word}':\")\n",
    "    for word, distance in similar_words:\n",
    "        print(f\"{word}: {distance:.3f}\")\n",
    "    \n",
    "    return fig_2d, fig_3d, visualizer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # Assuming you have your trained model and preprocessor\n",
    "    fig_2d, fig_3d, visualizer = visualize_embeddings(model, preprocessor)\n",
    "    \n",
    "    # Display the plots\n",
    "    fig_2d.show()\n",
    "    fig_3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Document QA system...\n",
      "Initialized toxicity filter with threshold 0.7\n",
      "Initialized OpenAI Document QA system with Self-Attention toxicity filtering\n",
      "Loading document: Character Conversations.pdf\n",
      "Splitting document into chunks...\n",
      "Created 9 text chunks\n",
      "\n",
      "Processing chunk 1/9\n",
      "Original chunk length: 464\n",
      "Total sentences: 6\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 5\n",
      "Chunk filtered out completely\n",
      "\n",
      "Processing chunk 2/9\n",
      "Original chunk length: 492\n",
      "Total sentences: 9\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 8\n",
      "Chunk filtered out completely\n",
      "\n",
      "Processing chunk 3/9\n",
      "Original chunk length: 487\n",
      "Total sentences: 8\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 7\n",
      "Chunk filtered out completely\n",
      "\n",
      "Processing chunk 4/9\n",
      "Original chunk length: 90\n",
      "Total sentences: 1\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 1\n",
      "Chunk filtered out completely\n",
      "\n",
      "Processing chunk 5/9\n",
      "Original chunk length: 477\n",
      "Total sentences: 10\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 9\n",
      "Chunk filtered out completely\n",
      "\n",
      "Processing chunk 6/9\n",
      "Original chunk length: 486\n",
      "Total sentences: 8\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 7\n",
      "Chunk filtered out completely\n",
      "\n",
      "Processing chunk 7/9\n",
      "Original chunk length: 412\n",
      "Total sentences: 9\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 8\n",
      "Chunk filtered out completely\n",
      "\n",
      "Processing chunk 8/9\n",
      "Original chunk length: 417\n",
      "Total sentences: 10\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 9\n",
      "Chunk filtered out completely\n",
      "\n",
      "Processing chunk 9/9\n",
      "Original chunk length: 372\n",
      "Total sentences: 11\n",
      "Clean sentences: 0\n",
      "Toxic sentences: 8\n",
      "Chunk filtered out completely\n",
      "\n",
      "Retained 0 clean text chunks\n",
      "Warning: No clean text chunks remained after filtering!\n",
      "Using original chunks with increased toxicity threshold...\n",
      "Error processing document: No usable text chunks after filtering. Please check document content.\n",
      "An error occurred: No usable text chunks after filtering. Please check document content.\n",
      "\n",
      "Required packages:\n",
      "pip install langchain langchain-openai openai pypdf faiss-cpu torch\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# [Previous Self-Attention Model Classes: MultiHeadAttention, PositionalEncoding, TransformerEncoderLayer, SelfAttentionClassifier]\n",
    "\n",
    "def create_attention_mask(seq_len):\n",
    "    \"\"\"Creates attention mask for self-attention\"\"\"\n",
    "    mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "    return ~mask\n",
    "\n",
    "# [Previous imports remain the same...]\n",
    "\n",
    "class IntegratedToxicityFilter:\n",
    "    \"\"\"Direct integration of self-attention model for toxicity filtering\"\"\"\n",
    "    def __init__(self, vocab_size=10000, device='cuda' if torch.cuda.is_available() else 'cpu', threshold=0.5):\n",
    "        self.device = device\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # Initialize self-attention model directly\n",
    "        self.model = SelfAttentionClassifier(\n",
    "            vocab_size=vocab_size,\n",
    "            d_model=512,\n",
    "            num_heads=8,\n",
    "            num_layers=6,\n",
    "            num_classes=2,\n",
    "            max_seq_length=512,\n",
    "            dropout=0.1\n",
    "        ).to(device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        print(f\"Initialized toxicity filter with threshold {threshold}\")\n",
    "    \n",
    "    def text_to_tensor(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"Convert text to tensor using basic tokenization\"\"\"\n",
    "        tokens = text.lower().split()\n",
    "        if not tokens:  # Handle empty text\n",
    "            tokens = ['<pad>']\n",
    "            \n",
    "        indices = [hash(token) % (self.model.embedding.num_embeddings - 1) + 1 for token in tokens]\n",
    "        if len(indices) > self.model.pos_encoding.pe.size(1):\n",
    "            indices = indices[:self.model.pos_encoding.pe.size(1)]\n",
    "        else:\n",
    "            indices += [0] * (self.model.pos_encoding.pe.size(1) - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "    \n",
    "    def is_toxic(self, text: str) -> bool:\n",
    "        \"\"\"Determines if text contains toxic content\"\"\"\n",
    "        if not text.strip():  # Handle empty text\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                text_tensor = self.text_to_tensor(text).unsqueeze(0).to(self.device)\n",
    "                mask = create_attention_mask(text_tensor.size(1)).to(self.device)\n",
    "                output = self.model(text_tensor, mask)\n",
    "                probabilities = torch.softmax(output, dim=1)\n",
    "                toxic_prob = probabilities[0][1].item()\n",
    "                return toxic_prob > self.threshold\n",
    "        except Exception as e:\n",
    "            print(f\"Error in toxicity detection: {str(e)}\")\n",
    "            return False  # Default to non-toxic on error\n",
    "\n",
    "    def filter_text(self, text: str, debug=False) -> str:\n",
    "        \"\"\"Filters toxic content by analyzing sentences\"\"\"\n",
    "        if not text.strip():\n",
    "            return \"\"\n",
    "            \n",
    "        sentences = text.split('.')\n",
    "        clean_sentences = []\n",
    "        toxic_sentences = []\n",
    "        \n",
    "        for sent in sentences:\n",
    "            sent = sent.strip()\n",
    "            if not sent:\n",
    "                continue\n",
    "                \n",
    "            if self.is_toxic(sent):\n",
    "                toxic_sentences.append(sent)\n",
    "            else:\n",
    "                clean_sentences.append(sent)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Total sentences: {len(sentences)}\")\n",
    "            print(f\"Clean sentences: {len(clean_sentences)}\")\n",
    "            print(f\"Toxic sentences: {len(toxic_sentences)}\")\n",
    "        \n",
    "        return '. '.join(clean_sentences)\n",
    "\n",
    "class OpenAIDocumentQA:\n",
    "    \"\"\"Document QA system combining OpenAI with self-attention toxicity filtering\"\"\"\n",
    "    def __init__(self, \n",
    "                 api_key: str,\n",
    "                 model_name: str = \"gpt-3.5-turbo\",\n",
    "                 temperature: float = 0.7,\n",
    "                 max_tokens: int = 500,\n",
    "                 toxic_threshold: float = 0.7):\n",
    "        \n",
    "        # Initialize toxic filter with adjusted threshold\n",
    "        self.toxic_filter = IntegratedToxicityFilter(threshold=toxic_threshold)\n",
    "        \n",
    "        # Initialize OpenAI components with API key\n",
    "        self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "        self.llm = ChatOpenAI(\n",
    "            openai_api_key=api_key,\n",
    "            model_name=model_name,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        \n",
    "        # Initialize text splitter\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50,\n",
    "            length_function=len\n",
    "        )\n",
    "        \n",
    "        self.vectorstore = None\n",
    "        self.qa_chain = None\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        \n",
    "        print(\"Initialized OpenAI Document QA system with Self-Attention toxicity filtering\")\n",
    "    \n",
    "    def load_document(self, pdf_path: str):\n",
    "        \"\"\"Loads and processes PDF document\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading document: {pdf_path}\")\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            pages = loader.load()\n",
    "            \n",
    "            print(\"Splitting document into chunks...\")\n",
    "            texts = self.text_splitter.split_documents(pages)\n",
    "            print(f\"Created {len(texts)} text chunks\")\n",
    "            \n",
    "            # Filter toxic content with debugging\n",
    "            clean_texts = []\n",
    "            for i, text in enumerate(texts):\n",
    "                print(f\"\\nProcessing chunk {i+1}/{len(texts)}\")\n",
    "                print(f\"Original chunk length: {len(text.page_content)}\")\n",
    "                \n",
    "                clean_content = self.toxic_filter.filter_text(text.page_content, debug=True)\n",
    "                \n",
    "                if clean_content.strip():\n",
    "                    text.page_content = clean_content\n",
    "                    clean_texts.append(text)\n",
    "                    print(f\"Clean chunk length: {len(clean_content)}\")\n",
    "                else:\n",
    "                    print(\"Chunk filtered out completely\")\n",
    "            \n",
    "            print(f\"\\nRetained {len(clean_texts)} clean text chunks\")\n",
    "            \n",
    "            if not clean_texts:\n",
    "                print(\"Warning: No clean text chunks remained after filtering!\")\n",
    "                print(\"Using original chunks with increased toxicity threshold...\")\n",
    "                self.toxic_filter.threshold = 0.9\n",
    "                clean_texts = []\n",
    "                for text in texts:\n",
    "                    clean_content = self.toxic_filter.filter_text(text.page_content)\n",
    "                    if clean_content.strip():\n",
    "                        text.page_content = clean_content\n",
    "                        clean_texts.append(text)\n",
    "            \n",
    "            if not clean_texts:\n",
    "                raise ValueError(\"No usable text chunks after filtering. Please check document content.\")\n",
    "            \n",
    "            # Create vector store\n",
    "            print(\"Creating vector store with OpenAI embeddings...\")\n",
    "            self.vectorstore = FAISS.from_documents(clean_texts, self.embeddings)\n",
    "            print(\"Document processing complete\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing document: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def setup_retrieval_qa(self):\n",
    "        \"\"\"Sets up the retrieval QA chain\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"Please load a document first\")\n",
    "            \n",
    "        self.qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vectorstore.as_retriever(\n",
    "                search_kwargs={\"k\": 3}\n",
    "            ),\n",
    "            return_source_documents=True\n",
    "        )\n",
    "    \n",
    "    def answer_question(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Answers questions with toxic content filtered\"\"\"\n",
    "        try:\n",
    "            if not self.qa_chain:\n",
    "                self.setup_retrieval_qa()\n",
    "            \n",
    "            print(f\"Processing question: {question}\")\n",
    "            \n",
    "            result = self.qa_chain({\"query\": question})\n",
    "            clean_answer = self.toxic_filter.filter_text(result['result'])\n",
    "            \n",
    "            sources = []\n",
    "            for doc in result['source_documents']:\n",
    "                sources.append({\n",
    "                    'content': doc.page_content[:200] + \"...\",\n",
    "                    'metadata': doc.metadata\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                'question': question,\n",
    "                'answer': clean_answer,\n",
    "                'sources': sources\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error answering question: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Get API key from user\n",
    "        api_key = input(\"Please enter your OpenAI API key: \")\n",
    "        \n",
    "        print(\"Initializing Document QA system...\")\n",
    "        doc_qa = OpenAIDocumentQA(\n",
    "            api_key=api_key,\n",
    "            toxic_threshold=0.7\n",
    "        )\n",
    "        \n",
    "        # Get PDF path\n",
    "        pdf_path = 'Character Conversations.pdf'\n",
    "        doc_qa.load_document(pdf_path)\n",
    "        \n",
    "        # Interactive QA\n",
    "        while True:\n",
    "            question = input(\"\\nEnter your question (or 'quit' to exit): \")\n",
    "            if question.lower() == 'quit':\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                result = doc_qa.answer_question(question)\n",
    "                print(f\"\\nAnswer: {result['answer']}\")\n",
    "                print(\"\\nSources:\")\n",
    "                for source in result['sources']:\n",
    "                    print(f\"- {source['content']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing question: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(\"\\nRequired packages:\")\n",
    "        print(\"pip install langchain langchain-openai openai pypdf faiss-cpu torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
